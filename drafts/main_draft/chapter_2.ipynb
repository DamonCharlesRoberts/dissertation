{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Do colors convey political information?\n",
        "\n",
        "<!--\n",
        "    # Notes:\n",
        "        ## Code:\n",
        "            ### pre-test:\n",
        "                #### 00_pre-test.py\n",
        "                #### table called pre-test\n",
        "            ### Scraping:\n",
        "                #### CAPD\n",
        "                    ##### Execute 01_capd_text_scraping.ipynb interactively\n",
        "                        ###### table called ch_1_capd_yard_signs\n",
        "                    ##### Execute 02_capd_img_scraping.ipynb interactively\n",
        "                        ###### table called ch_1_capd_yard_signs\n",
        "                    ##### Execute 03_capd_downloading_images.py\n",
        "                        ###### does so at end of 02_capd_img_scraping.ipynb\n",
        "                    ##### Execute 04_mit_election_lab_merge.py\n",
        "                        ###### does so in the some-script-execution block below\n",
        "        ## Writing:\n",
        "-->"
      ],
      "id": "a1956cc8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: python-setup-block\n",
        "\n",
        "# import modules\n",
        "    #* from environment\n",
        "import os # for path management\n",
        "import sys # for path management\n",
        "import numpy as np # for array management\n",
        "import pandas as pd # for dataframe management\n",
        "import cv2 # for color detection\n",
        "from matplotlib import pyplot as plt # for graphics\n",
        "from matplotlib import image as mpimg # for displaying images\n",
        "from IPython.display import display, Markdown # for displaying inline code\n",
        "    #* user-defined\n",
        "sys.path.append(\"../../code/\")\n",
        "from fun import preProcess"
      ],
      "id": "python-setup-block",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The systematic use of colors in campaign branding\n"
      ],
      "id": "0dd78225"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: some-script-execution\n",
        "#| eval: false\n",
        "import os\n",
        "\n",
        "os.system('../../code/03_capd_downloading_images.py')\n",
        "os.system('../../code/04_mit_election_lab_merge.py')\n",
        "os.system('../../code/05_color_detection.py')"
      ],
      "id": "some-script-execution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Descriptive analysis of the use of color in yard signs\n",
        "- Consider using district level fixed effects in a regression to show District PID $\\rightarrow$ Color selection\n",
        "\n",
        "To examine whether the use of colors on yard signs vary in systematic ways, I collect images from the 2018, 2020, and 2022 Congressional elections for the House of Representatives across the United States. These yard signs are pulled together on one website by the Center for American Politics and Design^[See: https://www.politicsanddesign.com/]. From this website, I am able to extract over 1,100 images for these three elections. I then combine this information with district-level data provided by the MIT election lab on election returns for candidates in these House elections ^[See: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2].\n",
        "\n",
        "With these data, I detect the percentage of the \"Republican Red\" and \"Democratic Blue\" on the yard signs and examine whether the 5-year smooth moving average of Democratic candidate vote share in that given district correlate. The purpose of this analysis is to examine the hypothesis that campaigns respond to the preferences of partisan voters and adjust their branding as a result. In this case, the branding being the color on the yard sign.\n",
        "\n",
        "To provide an example of how the color detection works, I collected the GOP logo used on their official Twitter account during the 2022 midterm election cycle. I load this image and convert it to a three-dimensional array that contains information about the GBR (reversed RBG) values for the pixels in that image. I then resize the images to be a standardized 224 $x$ 224 pixels. The computer is trained to detect a range of GBR values that encompass the official \"Republican Red\"^[lower values: (93, 9, 12), higher values: (236, 69, 75)]. For the broader exercise, I do it for the color white^[upper and lower values: (255, 255, 255)] and \"Democratic blue\"^[lower values: (0, 18, 26), higher values: (102, 212, 255)]. Once this range of values is specified, the computer detects the pixels that do not contain values within this pre-specified range and converts those values to represent the color black. @fig-color-detection-example presents this process.\n"
      ],
      "id": "8136024f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-color-detection-example\n",
        "#| layout-ncol: 2\n",
        "#| fig-cap: Detecting colors in the GOP logo\n",
        "#| fig-subcap:\n",
        "#|   - Resized original image\n",
        "#|   - Masked\n",
        "\n",
        "# Define colors to detect\n",
        "    #* White\n",
        "        #** Not defined. Default for colorDetector()\n",
        "    #* Red\n",
        "republican_red = [232, 27, 35] # target color\n",
        "red_lower = [93, 9, 12] # lower end of spectrum for red\n",
        "red_higher = [237, 69, 75] # higher end of spectrum for red\n",
        "\n",
        "# Load gop image to read\n",
        "img = cv2.imread(\"../../data/chapter_1/gop_2022.png\")\n",
        "\n",
        "# Detect colors\n",
        "    # create boundaries \n",
        "boundaries = [([red_lower[2], red_lower[1], red_lower[0]],[red_higher[2], red_higher[1], red_higher[0]])]\n",
        "    #print(\"boundaries correct\") \n",
        "    #print(boundaries)\n",
        "    # get information about original image\n",
        "    #width = img.shape[1] # get width of img\n",
        "    #height = img.shape[0] # get get height of img\n",
        "    # Transform image\n",
        "img_transformed = preProcess(img)\n",
        "    #print(\"img correct\")\n",
        "    # get information about transformed image\n",
        "    #width_t = img_transformed.shape[1] # get width of img_transformed\n",
        "    #height_t = img_transformed.shape[0] # get height of img_transformed\n",
        "    # calculate scale\n",
        "scale = ((img_transformed.shape[0]/img.shape[0]) + (img_transformed.shape[1]/img.shape[1]))/2\n",
        "    #print(\"scale correct\")\n",
        "for (lower, upper) in boundaries:\n",
        "    # adjust red_higher and red_lower to specific type\n",
        "    lower = np.array(lower, dtype = np.uint8)\n",
        "    upper = np.array(upper, dtype = np.uint8)\n",
        "    # take all values within color range and make it white; everything else black\n",
        "    mask = cv2.inRange(img_transformed, lower, upper)\n",
        "    # take all white values and put it on original image. keep black pixels black\n",
        "    result = cv2.bitwise_and(img_transformed, img_transformed, mask = mask)\n",
        "    # get ratio of non-black pixels\n",
        "    ratio = cv2.countNonZero(mask)/(img_transformed.size/(1/scale))\n",
        "    # calculate percentage of non-black pixels\n",
        "    percent = (ratio * 100)/scale\n",
        "cv2.imwrite(\"../../data/gop_2022_transformed.png\", img_transformed) # save transformed image\n",
        "\n",
        "cv2.imwrite(\"../../data/gop_2022_detected.png\", result) # save masked image\n",
        "\n",
        "img_transformed = mpimg.imread(\"../../data/gop_2022_transformed.png\") # load transformed image\n",
        "plt.imshow(img_transformed) # show img_transformed\n",
        "plt.axis(\"off\") # remove axes\n",
        "plt.show() # show plot\n",
        "\n",
        "img_masked = mpimg.imread(\"../../data/gop_2022_detected.png\") # load masked image\n",
        "plt.imshow(img_masked) # show img_masked\n",
        "plt.axis(\"off\") # remove axes\n",
        "plt.show() # show plot"
      ],
      "id": "fig-color-detection-example",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I then extract the values in the array that are non-black and calculate the percentage of non-black pixels (as depicted in @eq-img-color-percentage).  \n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{Color} \\% = \\frac{\\text{Non-black}}{\\text{Transformed}} \\times \\frac{\\text{Original}_{\\text{Height}} + \\text{Original}_{\\text{Width}}}{2\\text{Transformed}_{\\text{Height}} + 2\\text{Transformed}_{\\text{Width}}}\n",
        "$$ {#eq-img-color-percentage}"
      ],
      "id": "e0570a11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(Markdown(\"\"\" For the example in @fig-color-detection-example, about {percent} of the image is red.\"\"\".format(percent = f'{percent:.2f}')))"
      ],
      "id": "c357f3e4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}