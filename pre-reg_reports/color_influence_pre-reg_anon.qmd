---
title: |
  How do colors convey political information and effect individual attitudes?
repo: |
  For replication, go to: <https://github.com/DamonCharlesRoberts/dissertation>.
author:
  - name: Damon C. Roberts
    email: damon.roberts-1@colorado.edu
    orcid: 0000-0002-4360-3675
    title: PhD Candidate
    affiliations:
      - id: CU
        name: University of Colorado Boulder
        department: Political Science
        address: 333 UCB
        city: Boulder
        region: CO 
        postal-code: 80309-0333
abstract: |
  Are colors important to politics as a form of political information? In this project I argue that they are. Building upon existing theories of political information processing and common theories of information processing, attitude formation, and affect in neuroscience, I present a snap-judgement model of political information processing. In this model, colors provide automatic information about a politically-relevant object that may shape subsequent processing of more complex information that the political science literature is more familiar with. The model has important implications for how we consider the role that visual information has on political information processing and attitude formation. The model additionally provides clarity on motivations behind party branding and the ways in which information may activate partisan biases pre-consciously.
nonblind: blind
bibliography: "../assets/references.bib"
format:
  pdf:
    template: "../../../templates/manuscripts/apsr_template.tex"
    cite-method: biblatex
execute:
  echo: false
  warning: false
  message: false
params:
  os: windows
---

```{python}
#| label: setup-block
# import modules
    #* from environment
import os # for path management
import sys # for path management
import numpy as np # for array management
#import polars as pl # for dataframe management
import cv2 # for color detection
import matplotlib
from matplotlib import pyplot as plt # for graphics
from matplotlib import image as mpimg # for displaying images
from IPython.display import display, Markdown # for displaying inline code
    #* user-defined
sys.path.append("../code/")
from fun import colorDetector
```

# Introduction

Are colors important to politics? This project argues that they convey information that matters to campaigns and voters. People rely on more than purely political information to understand politics [@pietraszewski_et-al_2015_c]. To reduce cognitive load, the affiliation detection system allows for efficient social behavior prediction by associating various cues with a group. In politics, associating Black voters with the Democratic party and White voters with the Republican party is one example [@pietraszewski_et-al_2015_c]. As Americans consistently link the colors red and blue with the Republican and Democratic parties [@elving_2014_npr] as well as their connection to ideology [see @maestre_medero_2022_pr for example], respectively, we should explore whether color acts as an affiliative cue for individuals in American politics.

Existing theories of political information processing have yet to examine visual information more broadly. As a simple yet ubiquitous piece of visual information, color may have more influence over shaping political views than we give it credit. As visual information is processed automatically and faster than other forms of information [see @ames_et-al_2012_ohsn], I argue that it triggers associated neurological pathways that shape the subsequent information processing of the more traditionally considered types of political information. Such a process implies that the presence of politically-relevant colors has the potential to, directly and indirectly shape political attitudes.

I propose two studies to test these claims. Yard signs are a simple yet effective source of campaign branding for political candidates. They shape the attitudes of those who view them [@makse_et-al_2019_oup], and they can even aggregately shape electoral outcomes [@green_et-al_2016_es]. As yard signs are a simple and static form of campaign advertising, they cannot rely heavily on more complicated forms of information. One form of information they rely on and vary significantly on is color. With these characteristics, yard signs are an ideal candidate both from a statistical standpoint and also substantive. From a statistical standpoint, as they are static forms of party branding, they have fewer moving parts, reducing the statistical confounds that may increase Type I errors. From a substantive standpoint, while we understand that yard signs matter to campaigns, we have yet to explore whether the color choice of the yard sign matters.

In [Study 1](#sec-study-1), I propose an experiment that examines whether the public notice and their attitudes are shaped by "Republican Red" and "Democratic Blue" on the yard signs of a fictional candidate. In [Study 2](#sec-study-2), I examine whether campaigns perceive that the color of a yard sign has real-world effects on voters' perceptions of the candidate. I do this by examining how electoral context shapes variation in using these partisan colors. Second, I have informal interviews with campaign staff to determine what shapes the decisions about what colors to include on a campaign's yard sign.

I then present a pre-test that experimentally tests whether yard signs using "Republican Red," "Democrat Blue," and White lead to different perceptions of the candidate's political views. I find that a fictional candidate with a background of "Republican Red" are perceived to be more Republican, and a fictional candidate with a background of "Democrat Blue" are perceived to be more Democratic. I also find that Republican voters are more likely to report a willingness to vote for the candidate with "Republican Red" on the yard sign, and Democratic voters are more likely to vote for the candidate with "Democrat Blue" on the yard sign.

# The role of visual information in politics

As the rise of television consumption necessitated a change in the focus of the medium in the research for political communication scholars [@hall-jamieson_2014_ohpc], so does the rise of image-based social media. For several methodological and disciplinary reasons, the visual aspects of television were of little focus in the literature [@bucy_joo_2021_ijpp]. However, with the trend toward ubiquitous use of the public to use image-dominant social media platforms like TikTok and Instagram, news organizations and politicians have responded. They are relatively active on these platforms as well. In response, we, as scholars, need to make this transition to integrate the role of simple visual information into our theories of political information processing (abbreviated as *pip*) and attitude formation.

Some scholars make this same argument. A central theme of an edited issue of *The International Journal of Press/Politics* is that visual politics is understudied; yet important [@lilleker_2019_pm]. Those who are engaged in these questions attribute these challenges to methodological and the requirement for the difficult task of interdisciplinary theorizing to engage in such questions [@gerodimos_2019_pm;@bucy_joo_2021_ijpp]. 

How does politically-relevant visual information matter to politics? From an evolutionary-biological perspective, visual information has been a common source of information for millions of years that a variety of single-and-multi-cell organisms rely upon to evaluate their environment [see @grabe_bucy_2009_oup, Chapter 1 for a useful discussion]. Visual information processing, as an ancient biological invention, the human brain is organized around the processing of it. Reflecting on this, many neuroscience scholars argue that visual information is the fastest form of information processing for humans. For example, even complex visual information, such as the warmth expressed in someone's facial features, is automatically and subconsciously processed in only about 33'ms' [@ames_et-al_2012_ohsn].

Approached from a different perspective, as humans are cognitive misers \index{cognitive misers}, visual information in the realm of politics provides efficient information to voters about politically-relevant actors and events [@lilleker_2019_pm]. Evidence suggests that voters rely on simple visual information in the background of an image to infer the ideological position [@dan_arendt_2021_ijpp] and that their coverage reflects electability perceptions [@stewart_et-al_2021_ijpp] -- which influences reported desire to vote for the candidate. Images posted on social media by politicians provide more personalized information about them, and they take on their own styles [@lindholm_et-al_2021_ijpp; @peng_2021_ijpp], reflecting that it is an alternative source of information curated to attract support. Evidence suggests that even simple party branding on yard signs has an emotional appeal and encourages a shift in attitudes toward the person who owns the yard sign [@makse_et-al_2019_oup]. That is, even branding as simple as yard signs appears to influence the attitudes of those who view them. However, like all types of party branding, there remain questions about the individual visual components' contribution.

While visual politics is enjoying more attention from social scientists, there still needs to be more focus on the simplest visual information: color. In the context of the United States, the "Republican red" and "Democratic blue" is a relatively recent invention that likely has significant import in an era of significant effort by the parties to distinguish themselves from each other [@clifford_2020_pb] and where voters toe the party line [@utych_2020_es]. Since the 2000 presidential election, the media have consistently used red on their electoral maps in "horserace" journalism to represent Republicans and blue to represent Democrats [@elving_2014_npr]. The supposed consequence is that Democrats now report a preference for the color blue over the color red, and Republicans report a preference for the color red over the color blue [@schloss_palmer_2014_pbr]. Beyond this, however, we have yet to develop and test theories about color's broader impacts on political information processing and attitude formation.

As the broader field of study of visual politics is under-theorized, theorizing about the use of color as a form of information is also quite limited -- perhaps even more so. The literature that does exist argues that colors are a source of visual information to classify more abstract concepts for voters. For example, in western Europe, voters are better at connecting the ideological positioning of a party with the color they use in their branding; the longer-surviving and more prominent the party is [@casiraghi_et-al_2022_pp]. The use of politically-relevant colors activates biases toward pre-existing ideological and partisan preferences among voters in a Spanish sample [@maestre_medero_2022_pr]. It remains unclear, however, what particular psychological mechanism drives this. Furthermore, how even colors, as a form of political information, are organized into a schema that allows voters to quickly access so that they construct political attitudes or how they moderate the effects of other types of political information on attitude formation. As a jumping-off point, we can turn to the literature on political information processing (heretofore abbreviated as *pip*)\index{political information processing}. 

The first prominent model of *pip* derives from rational choice perspectives. The memory-based model of *pip* views attitudes as a weighted collection of prior information [see @zaller_1992_cup]. As individuals receive new information, they organize it into a schema that is relative to prior objects they already have encoded. By encoding this new information, the model predicts that individuals incorporate this new object with similar objects to form an attitude. This schema then may be more accessible in similar contexts and may then sample from its elements when prompted to express a political attitude. While the Receive-Accept-Sample (RAS) model accepts the view that expressed attitudes are a weighting of information most accessible at the time of attitude expression [@zaller_feldman_1992_ajps], it still presupposes that the weighting is an average of prior information.

The second prominent model challenges this latter point. The online model of *pip* contends that individuals do not evenly weigh information, but that whether they even store it in their long-term memory to access later is biased in the direction of supporting pre-existing attitudes [@lodge_taber_2013_cup]; this phenomenon is referred to as motivated reasoning by the psychology literature [@kunda_1990_pb]. This model suggests that people ignore new information that goes against their prior beliefs and that information confirmatory of their preferences is quicker to access -- referred to as hot cognition [@lodge_taber_2013_cup].

The online model conceptualizes this underlying information encoding and attitude retrieval mechanism as automatic [@lodge_taber_2013_cup]. This occurs due to the information's strong associations with valanced appraisals of the information guiding the attitude [@lodge_taber_2013_cup]. This brings political scientists closer to the dominant conceptualizations among neuroscientists and psychologists concerned with memory retrieval, encoding, and attitude formation [see @fazio_2007_sc]. Namely, that memories are encoded and retrieved quickly based on associations due to their association with valanced appraisals [@kensinger_fields_2022_ohhum]. What remains unexplored is how visual information such as color may prime individuals to engage in motivated reasoning pre-consciously. If they keep their attention on the object, what paths are activated by such information?


# Integrating color into a model of political information processing

Existing models of *pip* primarily focus on complex forms of political information such as text. As individuals process visual information before other sorts of information, we might expect that they may form a snap judgment or the initial appraisal of an object. This has several important implications, from suggesting that we broaden our theories of *pip* to reconsider what constitutes politically-relevant information to what it means for our substantive understanding of how people process political information and the calculus involved in political attitude formation.

Though the online information processing model goes a long way to inform us about how our physiology engages attitude formation and retrieval, the types of information it considers necessarily limits the theory's applicability to other forms of political information. Color and other simple visual information are processed much quicker and occur more frequently than text-based information [@mehta_zhu_2009_s]. As the color and other visual information are processed differently, we should also consider its use as political information. As visual information is affectively encoded [@cimbalo_et-al_1978_jgp], it can affect the affective state and processing of more complex information, such as text. The visual information provides a snap judgment or an impression of the object through faster processing and activates particular neurological processes that influence subsequent information appraisals [@ames_et-al_2012_ohsn]. This implies that the conclusions drawn from such *pip* models may be systematically biased without considering the upstream effects of non-text information; such as simple visual information like color.

Before expanding upon the role of colors in shaping political attitudes, let me first define an attitude as a concept. An attitude represents an accessible, valanced evaluation of associated prior information and experiences. This conceptualization fits with that of the Object-Evaluation Associations Model [@fazio_2007_sc]. As opposed to viewing attitudes as a latent collection of memories, as is done in the memory-based model of *pip* [@zaller_feldman_1992_ajps], it views attitudes as measurable evaluations of memories. As memories are at the core of an attitude, the association of memories with its evaluative component [see @kensinger_fields_2022_ohhum] contributes to the perspective that attitudes are affective. This implies that we should be able to measure attitudes but that such an operationalization requires careful consideration of the context's role in any given measure of an attitude as they result from memories [@fazio_2007_sc].

In line with the existing models of *pip*, I conceptualize attitudes as associative. This means that attitudes may be unstable - not stochastically, in any case. As attitudes are associative, they manifest slightly differently depending on the associative paths activated [@fazio_2007_sc]. The retrieval of relevant memories to the attitude depends on many factors, such as the recency of the event, the similarity of the context, and the importance or salience of the memory [@kahana_et-al_2022_ohhum]. This means that the memories retrieved to contribute to an attitude are quite variable. However, to understand where that variability comes from, we must understand the deeper processes influencing how information is encoded and later retrieved. This illustrates my need to build upon the reigning models of *pip*. Colors may act as a contextual feature that may lead to this variability in how a given set of political information may shape attitudes.

Colors are associative and are affectively encoded [@cimbalo_et-al_1978_jgp]. When individuals access a memory, they do not just recall an object, but they may recall visual information such as the color of an object. As visual information like colors is quickly processed and encoded, they are quickly retrieved with their associative memories and can do so unconsciously [@mehta_zhu_2009_s]. As they are affectively encoded, their associations with particular memory contribute to the evaluative component of the memory. For example, individuals associate colors like red with anger and arousal [@valdez_mehrabian_1994], whereas individuals associate blue with things like happiness and pleasure [@dandrade_egan_1974_ae]. This means that colors are compelling as contextual information shaping the subsequent processing and integration of "traditional" forms of political information to construct an attitude. As the preference for a particular color correlates with political attitudes [@schloss_palmer_2014_pbr], they may have some causal influence upon political attitudes; rather than just a correlation with them.

According to the literature in affective neuroscience, visual information is processed in parts of the brain, such as the visual cortex [@goldstein_brockmole_2017_cl]. This will activate other areas of the brain and will make associated paths "hot." One such area is the amygdala. Neuroscientists believe that as visual information is quickly and subconsciously processed, the amygdala takes and appraises it based on the paths it activated; this generates a simple affective response to such information [@winkielman_et-al_2011_ohsn]. More complex, categorical emotion occurs later in conscious processing [@winkielman_et-al_2011_ohsn]. Once politically-relevant visual information is detected, the retina passes it to the brain. Once there, the brain attempts to classify the visual information by activating networks of neurons associated with the current information. With these activated pathways, the brain also attempts to appraise such information based on quick classification. For attitude formation, this implies that, as memories are affectively encoded [@kensinger_fields_2022_ohhum], these memories help areas such as the amygdala to appraise the current information. 

These fast affective classifications are valanced rather than the more laborious categorization of specific emotions (e.g., anger, anxiety, fear, happy). What this means is that rather than conceptualizing the affective component of this process in line with the popular conceptualizations in political science, such as affective intelligence theory [@marcus_2000_arps], I conceptualize affect as a more extensive system that considers emotion only as a conscious classification process that occurs later than initial valanced appraisals of an object [@sander_2013_chhan;@ralph_anderson_2018_pup]. That is, emotion -- the complex classification of appraisals -- is a conscious component of affect. The pre-conscious process of affect occurs first with the simple and automatic valanced classification of an object [@winkielman_et-al_2011_ohsn;@dror_2017_er].

The pre-conscious appraisals of the visual information one encounter encourage particular behavioral and attitudinal motivations [@valentino_et-al_2011_jop;@ralph_anderson_2018_pup]. This has evolutionary roots for survival [@ralph_anderson_2018_pup;@parker_2003_p]. While affective appraisals can lead to complex motivations, such as anxiety leading to motivations for information seeking [@marcus_2000_arps], affective appraisals are valanced and are more automatic [@winkielman_et-al_2011_ohsn]. These affective appraisals lead to a desire to either retract or engage more with the object [@valentino_et-al_2011_jop]. The snap judgment resulting from the automatic processing of politically relevant visual information should likely lead to an affective response that motivates either a desire to engage more with the object or disengage. 

While the visual information may encourage a particular immediate reaction to engage or disengage from the information, subsequent information processing and more conscious processing adjusts this initial appraisal generated by the snap judgment [@kensinger_fields_2022_ohhum]. While subsequent information may amend one's snap-judgment, the snap-judgment nevertheless influences the processing of subsequent information by activating particular paths, which is later encoded as associated with the object as it converts to a memory [@lodge_taber_2013_cup;@kensinger_fields_2022_ohhum].  

@fig-snap-judgement-model-chapter presents an illustration of the snap-judgment model.

```{mermaid}
%%| label: fig-snap-judgement-model-chapter
%%| fig-cap: Snap-judgement model
%%| fig-width: 6
%%{init: {'theme':'base', 'themeVariables':{'primaryColor':'#ffffff', 'primaryBorderColor': '#000000'}}}%%

graph TD
    A[Detection of politically-relevant visual information] --> B(Activation of retrieval mechanism)
    B --> C[Memory and contiguous paths hot]
    C --> D[Appraisal of hot autonomous nervous system]
    D --> E1[Negative Valence]
    D --> E2[Positive Valence]
    E1 --> F1[Disengagement motivation]
    E2 --> F2[Attention activated]
    F1 --> |Neg. new information| G1[Encoded as negative]
    F1 --> |Pos. new information| G2[Encoded as positive]
    F2 --> |Neg. new information| G3[Encoded as negative]
    F2 --> |Pos. new information| G4[Encoded as positive]
    G1 --> H1[Strengthens negative path]
    G2 --> H2[Weakens negative path]
    G3 --> H3[Weakens positive path]
    G4 --> H4[Strengthens positive path]
    G2 --> |forgotten| H1
    H2 --> |reinforced| G2
    H3 --> |reinforced| G3
    G3 --> |forgotten| H4

```

All of this means for *pip* is that when we view political events or consume political information with a visual component, we are going to encode visual information along with it. Taking expectations formed from theories of motivated reasoning [see @kunda_1990_pb], I expect that the visual information that we encode with it is likely congruent with the evaluation of the object; we are likely to be unwilling to encode the visual information that is not congruent with the visual information as we do with text-based political information [see @lodge_taber_2013_cup]. That is because unconsciously, we will experience a motivation to disengage from such information as soon as we appraise the visual aspects of an object as incongruent with existing attitudes and, therefore, be uncomfortable. It should also influence how we retrieve memories when we encounter new information, which will affect the attitudes we express. Additionally, this predicts that we will spend less time processing, accessing, and encoding congruent information [@lodge_taber_2013_cup].

Let me illustrate the snap-judgment model with a common experience for residents of the United States. Say you are driving down a highway. At 65 miles an hour, you are traveling at about 95 feet per second at this speed. You split your attention. You focus your eyes on the conditions of the road in front of you, the cars in front of you, and the rear-view mirror where your kids are either dropping food in the crevice between the seats or trying to grab your attention. Out of the corner of your eye, you see a sign. It is not a road sign because it is not on the familiar white or yellow background with black lettering. It is election season. You correctly infer that it is a political yard sign. In this split second, you notice the sign's color and may see a name: Mitch McConnell. You now are racking your brain to think about who that is. If you are politically engaged, you might come to that recognition of the name quickly or it may take you significantly longer if you are less politically engaged [see @kahana_et-al_2022_ohhum]. You figure out that they are a Republican politician. You may have come to this with the help of the fact that every year you have seen yard signs on this stretch of highway. You know that when you see those electoral maps pop up on your news app on your phone that the electoral forecasts always represent Republican support with red and blue for Democrats. Once you have figured out who this person is, with the help of this other information, you react: "ugh, that guy is too loyal to Trump" or "yeah! He's loyal to Trump". You've expressed a political attitude.

What the snap-judgment model predicts is happening in your head is that as soon as the light that bounces off the sign to produce a particular wavelength hits your eyes, your brain is already trying to make sense of this information. This is a valuable tool for survival that biology has optimized for millions of years [@parker_2003_p]. Rather than slowly processing the visual information and finding yourself in the jaws of a predator or processing it quickly but forming the wrong impression and running away from a friend, the brain processes the information quickly and subconsciously [@newell_1990_hup]. To make sense of such information, it accesses familiar information similar to what it is currently attempting to process for efficiency [@kahana_et-al_2022_ohhum]. This is accessing memories and contains valanced information [@kensinger_fields_2022_ohhum]: should I avoid this, or is it pleasant? Once the brain has finished such processing, it can pass its prediction to your conscious memory. Once you form a reflex of avoid or approach, this opens up space for your brain to process the more complex information: to take the patterns of the light as shapes that construct symbols and letters. This comes later because this information not only requires access to information about what it *is* but also what it *means*; once you understand what it means, you have the information necessary to evaluate it. 

The snap-judgment model predicts that you first process the colors of the yard sign. You access associative memory to figure out what those particular wavelengths represent: red, white, blue? As these colors are associated with different emotional states [see @cimbalo_et-al_1978_jgp] and the resulting behavioral consequences, your brain starts sending signals to the rest of your body to prepare it to react [see @sander_2013_chhan;@dror_2017_er]. You now need to figure out what the rest of that information was. What were the patterns of that light? It appears that there were some white letters on the sign. There was an "E," a "L," an "E," a "C," and a "T." That creates the word "ELECT." Meaning to vote for. There were some more letters on the sign: an "M," an "I," a "T," a "C," and an "H." A name. The full name is "Mitch McConnell". Since it is about politics, it must be a politician named Mitch McConnell. Now imagine the information was the same, except the color was blue. You may take more time to figure out how that Mitch McConnell person is and come to your reaction to seeing their yard sign. This is because, without the color red, you first are thinking about Democrats who are named Mitch McConnell. Only when you come up empty on your mental Rolodex do you figure out that it is the Republican Mitch McConnell.

How do you react to the color and then to the name? Social groupings are not simply abstract concepts invented by social psychologists; our neurobiology reflects them. For example, researchers find activation of parts of the brain, such as the anterior insula, when we see someone in our social group outperformed by someone from the out-group [see @zink_barter_2012_ohsn]. The anterior insula activity is associated with physical and emotional pain, not just for ourselves but also for others [@adolphs_janowski_2011_ohsn]. Others have also observed that when seeing someone part of a high-status social group, there is an increase in activity in the sensorimotor cortex and supplementary motor area, indicating more activity in the areas of the brain that encourage movement [@zink_et-al_2008_n]. Visual information about someone in your social group speeds up processing, is more salient, and demands more attention than visual information about an object outside your social group [@zink_barter_2012_ohsn].

There is significant evidence supporting the theory that our partisan identification reflects more than just our attitudes about politics but a social identity [see @campbell_et-al_1960_jws; @mason_2018_cup] that guides our attitudes [see @achen_bartels_2016_pup; @white_et-al_2014_apsr; also @bullock_2011_apsr]. As our political attitudes reflect shared views among co-partisans [@pickup_et-al_2020_pb], the congruence between political information and our partisan identification influences our reactions to such political information. This means that the visual information we glean from politics will likely motivate those neurological features of social groups and explain the resulting behavioral manifestations reacting to such information. That information is also likely to be processed at different rates as well. That is, while visual information carries general affective associations, we should also expect associations between politically-relevant colors with partisan identification.

From this discussion, I expect the following: that individuals do pay attention to the colors used in campaign branding (***$H_{1}$***); that these colors that they notice shape perceptions about the person and ideological symbol represented in the branding -- meaning that they express different levels of preference for receiving more information that is similar to what they saw and their levels of preference for supporting such a campaign (***$H_{2}$***); that the consistency of information explains more positive perceptions -- simple visual information with more complex "traditional" information (***$H_{3}$***); this positive and consistent information is processed quicker than negative and inconsistent, negative and consistent, and positive and inconsistent information (***$H_{4}$***); and finally that campaigns make strategic choices about their branding to attract voters (***$H_{5}$***) in line with their primary objective of reelection [@fenno_1973_lb;@mayhew_1974_yup].

# Study 1 {#sec-study-1}

The purpose of [Study 1](#sec-study-1) is to examine the effects of color in a common form of campaign branding -- yard signs -- on the attitudes of the observer. Evidence suggests that yard signs *do* matter in shaping political attitudes [@makse_et-al_2019_oup], vote intentions [@makse_et-al_2019_oup], and even electoral outcomes[@green_et-al_2016_es]. As they are simple, cheap, intrusive, and common forms of campaign branding, they provide a conservative test of the effects of color in campaign branding. Using yard signs in this study, I test the first four hypotheses I derive from the snap-judgment model. First, [Study 1](#sec-study-1) tests the claim that individuals do indeed notice the color of electoral yard signs. Next, it tests the claim that these colors that individuals detect influence the viewer's evaluations of the yard sign and the candidate represented on it. [Study 1](#sec-study-1) then tests the claim that the effects on perception are moderated by how consistent the color is with the more complex information displayed on the yard sign. Furthermore, finally, [Study 1](#sec-study-1) examines whether positive information that contains consistency is processed quicker than negative or inconsistent information. That is, do partisans quickly detect and encode information from a clearly co-partisan political candidate?

## Design

I recruit 1,000 participants from Prolific.^[I pay subjects a rate of $12.00 per hour. On top of the price per participant, Prolific charges a 30% servicing fee and an additional fee to guarantee a nationally representative sample.] After providing informed consent to participate in the study, Prolific redirects subjects to Pavlovia^[Pavolovia allows for researchers to host and run open source experiments for about $0.20 per participant (to cover their server costs). I use it primarily to integrate the JavaScript components for my experimental design.] and are provided with a demographics and political attitudes questionnaire. This questionnaire includes common questions about the participant's ascriptive and descriptive characteristics and about the participant's political ideology, partisan identification, interest in politics, and political knowledge.

I include those questions in the questionnaire due to expectations that they may act as confounds in my hypotheses. As political knowledge intertwines with the strength to which an individual identifies with a political party [@delli-carpini_keeter_1996_yup], I expect that political knowledge is an important confounder in my tests of $H_2$, $H_3$, and $H_4$. Therefore, I include a standard battery for assessing political knowledge. As political knowledge is shaped by levels of interest in politics as well [@delli-carpini_keeter_1996_yup], I include the standard question to assess levels of self-reported interest in politics. I additionally include some questions collecting information on participants' ascriptive and descriptive characteristics such as age, education, gender identity, and racial identity, as a number of these are correlates with partisan identification [see @campbell_et-al_1960_jws;@mason_2018_cup].

Additionally, I include a question about the respondent's sex assigned at birth and about whether they have received a diagnosis of any color blindness. As some individuals may possess undiagnosed colorblindness, asking about their sex assists in covariate balance. I additionally include four open-ended questions asking participants to describe (1) their "first memory of a political event," (2) "what occurred in the most recent political event" they encountered, (3) how they "keep up-to-date with current political events," and (4) "what occurred in the most recent non-political event" they encountered. The use of multiple open-ended questions helps provide an attention check and identify duplicated responses for those spoofing IP addresses with a VPN [see @kennedy_et-al_2021_poq].

I then present participants with an instruction screen informing them of the task for the experiment. In the first trial of the experiment, participants I randomly presented participants with two of three possible yard signs, one at a time. These yard signs are simple with the text "Vote for Riley" and a solid background color of either "Republican Red," "Democratic Blue," or White.^[See the supplementary information to view all of the stimuli used in [Study 1](#sec-study-1).] There is an added component to this, however.

Rather than use eye-tracking devices and software, I instead use Mouseview.js [see @anwyl-irvine_et-al_2022_brm], which either blocks out or blurs a large portion of the participant's screen and encourages them to move their mouse to view different parts of the screen in isolation. As the participants move their cursor around the screen, it tracks the coordinates of the cursor along with the "dwell" time of the cursor in that particular coordinate. One primary benefit of Mouseview.js is that it allows researchers to field their experiments outside of a lab-based setting -- while providing results that robustly correlate with the results from a design employing eye-tracking hardware [@anwyl-irvine_et-al_2022_brm]. This allows researchers to rely less on convenience samples, which are common with eye-tracking studies. For my design, I am particularly concerned about reliance on a convenience sample due to variations in participants' ability to detect and process color in the U.S. population relative to a student sample. This means that Mouseview.js is a handy tool for my study. A published pilot version of the experiment used in [Study 1](#sec-study-1) on [Pavlovia](https://run.pavlovia.org/damoncroberts/diss_ch_1_pre-reg/?__pilotToken=c74d97b01eae257e44aa9d5bade97baf&__oauthToken=9a645f267f9b83c8ebb48e60093bae5a746da56a6c824b8343389a9329fa2365).

When viewing each yard sign in the first trial, there is a blur over a substantial portion of the screen. At any given point in time, participants can view only 8% of the image without an obstruction, which simulates the observation that we typically foveate on about 8% of our available visual field at any given time [@wedel_pieters]. Participants move their cursor to explore the yard sign. I allot 5000 ms to perform the exploration until the image goes away to encourage a consistent and short duration to explore the image.^[In marketing research, some studies give participants about 6000 milliseconds in eye-tracking studies to examine a brand and to formulate an intention to purchase a product or not [@wedel_pieters]. With Mouseview.js, a study examining the tool's correlation with optical responses to viewing disgust-and-pleasure-evoking images uses 10000 milliseconds; but is intended to be an extended amount of time [@anwyl-irvine_et-al_2022_brm].] After exploring each image, I asked participants what colors were on the yard sign and whether they felt that the candidate represented on the yard sign was a Democrat, a Republican, or Neither. After viewing both images, I ask subjects to indicate their preference among the two images. To ensure that participants have a standardized initial placement of their cursor, I display a blank page before viewing the yard sign that requires participants to click a "Next" button. Immediately after clicking "Next," participants are shown the yard sign. The goal is to ensure that variation in where participants explore the image is not dependent on a non-standard starting point for their cursor. I additionally utilize a gaussian blur for the overlay of the image rather than a solid overlay obstructing the participant's view. This gaussian blur allows participants to see a blurred visual field beyond the cursor. This allows participants to see enough to take purposeful action to explore blurred parts of the image that attract them [@anwyl-irvine_et-al_2022_brm].

There are three more trials that are much like the first trial. What is different between the two other trials is that I vary the amount of color that is on the yard signs (trials 2 and 3). I provide more textual information that deviates from the association of Republicans with red and Democrats with blue (trial 4).

## Do individuals notice color in political branding?

To address this first question, I use two measures of a participant's attention toward the colors on the yard sign. I collected the first measure through a question posed to the participant after viewing each yard sign, "what color was the yard sign?". The second measure is more implicit than the first: it accounts for the time someone's mouse hovered over the non-text elements of the yard sign relative to how long their mouse hovered over the text. The self-reported measure allows us to examine the conscious detection of color, while the more implicit measure allows us to examine where individuals' attention goes: toward the color or the text.

This is primarily a descriptive exercise, and I intend to compare the differences in measures between the "non-partisan" (white) yard signs and the partisan (red and blue) yard signs. I will examine the differences in measures between the partisan yard signs among self-identified partisan respondents.

## Do colors shape perceptions of political objects?

To address the following question of whether the colors affect perceptions of the candidate and the yard sign, I ask participants to report whether they perceived the candidate to be a partisan -- either Republican, Democrat, or as non-partisan. Everything on the yard signs remains constant except for the color. As representations of ideology are associated with more than just political views but things like space [@mills_et-al_2016_bbr] and color [@maestre_medero_2022_pr], differences between respondents on the perceived political affiliations of the candidate should be more than stochastic differences. However, differences occur based on the associations between red and blue with partisanship and the lack of political information that the color white conveys.

I examine differences in respondents' reported perceptions of the candidate's partisan affiliation. As respondents see multiple yard signs, I intend to calculate the Individual Marginal Component Effect (IMCE), which allows me to view the within-individual differences [@zhirkov_2022_pa] in perceptions with varying color-based information among the yard signs they view. I also am able to calculate the Average Marginal Component Effect (AMCE) by examining the average difference in perceptions among subgroups that vary on the level of political interest, partisan strength, and level of political knowledge. 

## Do these perceptions require consistency between information types?

Another hypothesis derived from the snap-judgment model suggests that inconsistency in the yard sign's visual information will lead to more mixed perceptions of the candidate's political stances. The design of the latter trials in the study presents yard signs with mixtures of non-partisan and out-partisan colors. For example, primarily red and presumably Republican yard signs, but has some blue or white in them.

I take the same analytical strategy to address this question as I did before. I estimate the IMCE and AMCE among respondents. I should expect that the trials that use less "consistent" visual information demonstrate more ambivalence among respondents in their reported perceptions of the politician's positions. Specifically, I expect that participants will perceive the yard signs that have both red and blue on them as more moderate and that the higher proportion of the color red or blue among the two colors will lead respondents, on average, to be more likely to believe that the candidate leans more Republican or Democratic.

## Do partisans process co-partisan branding faster?

The other analytical tasks do not examine expectations derived from the motivated reasoning portion of the model. That is, do people process in-group information faster than out-group information? There is evidence of these tendencies in political circumstances [@lodge_taber_2013_cup]. 

To examine whether motivated reasoning is also active with the processing of politically-relevant color, I examine the difference between the amount of time between the start of viewing a stimulus and clicking "Next" to stop viewing the stimulus among those who were viewing a presumed co-partisan yard sign relative to those viewing a presumed out-partisan yard sign. As motivated reasoning tends to be more prevalent among strong partisans and those highly knowledgeable and interested in politics [@lodge_taber_2013_cup], I control for responses to the pre-treatment knowledge, interest, and partisan strength batteries.

# Study 2 {#sec-study-2}

[Study 1](#sec-study-1) presents evidence in support of the snap-judgment model in a relatively artificial way. The yard signs presented as stimuli are elementary in information content and design. Furthermore, viewing yard signs in real-world scenarios does not occur through a computer screen with an overlay allowing individuals to observe only a fraction of the screen simultaneously. 

One way to examine the real-world effects of color on decisions about campaign branding is to go directly to the experts. If the effects of [Study 1](#sec-study-1) hold up in natural conditions, we should expect that campaigns do not include the same design elements across electoral contexts. If the color of a yard sign does indeed matter and its electoral effects depend on the perceptions of potential voters, we should expect that campaigns are less likely to place yard signs with a large amount of Red or Blue. For example, in districts that contain relatively few co-partisans.

## Do branding choices reflect electoral context?

```{python}
#| label: some-script-execution
#| eval: false
import os
os.system('../../code/03_capd_downloading_images.py')
os.system('../../code/04_mit_election_lab_merge.py')
os.system('../../code/05_color_detection.py')
```

To examine whether the use of colors on yard signs varies systematically depending on the electoral context, I collect images from 2018, 2020, and 2022 Congressional elections for the House of Representatives across the United States. These yard signs are pulled together on one website by the Center for American Politics and Design^[See: https://www.politicsanddesign.com/]. I can extract over 1,100 images from this website for these three elections. I then combine this information with district-level data from the MIT election lab on election returns for candidates in these House elections ^[See: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2].

With these data, I detect the percentage of the "Republican Red" and "Democratic Blue" on the yard signs and examine whether the 5-year smooth moving average of Democratic candidate vote share in that given district correlate. This analysis aims to examine the hypothesis that campaigns respond to the preferences of partisan voters and adjust their branding as a result. In this case, the branding is the color of the yard sign.

I collected the GOP logo used on their official Twitter account during the 2022 midterm election cycle to provide an example of how color detection works. I load this image and convert it to a three-dimensional array that contains information about the GBR (reversed RBG) values for the pixels in that image. I resized the images to be a standardized 224 $x$ 224 pixels. I train the computer to detect a range of GBR values that encompass the official "Republican Red" ^[lower values: (93, 9, 12), higher values: (236, 69, 75)]. For the broader exercise, I do it for the color white^[upper and lower values: (255, 255, 255)] and "Democratic blue" ^[lower values: (0, 18, 26), higher values: (102, 212, 255)]. Once this range of values is specified, the computer detects the pixels that do not contain values within this pre-specified range and converts those values to represent the color black. @fig-color-detection-example presents this process.

```{python}
#| label: example detection
#| echo: false
# Define colors to detect
    #* White
        #** Not defined. Default for colorDetector()
    #* Red
republican_red = [232, 27, 35] # target color
red_lower = [93, 9, 12] # lower end of spectrum for red
red_higher = [237, 69, 75] # higher end of spectrum for red

# Load gop image to read
img = cv2.imread("../pre-reg_reports/data/gop_2022.png")

# Detect colors
percent, img_transformed, result = colorDetector(img = img, color_upper = red_higher, color_lower = red_lower)

transformed=cv2.imwrite("../pre-reg_reports/data/gop_2022_transformed.png", img_transformed) # save transformed image

masked=cv2.imwrite("../pre-reg_reports/data/gop_2022_detected.png", result) # save masked image
```

:::{#fig-color-detection-example layout-ncol=2}
![Resized original image]("../pre-reg_reports/data/gop_2022_transformed.png"){#fig-resized}

![Masked]("../pre-reg_reports/data/gop_2022_detected.png"){#fig-masked}

Detecting colors in the GOP logo
:::

I then extract the values in the array that are non-black and calculate the percentage of non-black pixels (as depicted in @eq-img-color-percentage).  

$$
\text{Color} \% = \frac{\text{Non-black}}{\text{Transformed}} \times \frac{\text{Original}_{\text{Height}} + \text{Original}_{\text{Width}}}{2\text{Transformed}_{\text{Height}} + 2\text{Transformed}_{\text{Width}}}
$$ {#eq-img-color-percentage}

```{python}
Markdown(""" For the example in @fig-color-detection-example, about {percent} of the image is red.""".format(percent = f'{percent:.2f}'))
```

With these data, I estimate a mixed effects model with intercept random effects at the district level and intercept fixed effects at the election year level to examine the district and within election year differences between choices to employ more "partisan" colors on a yard sign based on historical data on the electoral performance of partisan and non-partisan candidates for each district.


## Is it *only* electoral differences that shape a campaign's choices?

While this provides valuable evidence suggesting systematic differences in choices among campaigns, there is still an open question of whether these differences are *only* the result of electoral differences or if candidate differences influence this; after all, candidates can shape their campaigns. 

Therefore, I reach out to several relatively easy-to-contact campaign staff for national campaigns and ask them, "how do you decide what colors to put on a yard sign?" With the handful of these informal interviews, I intend to see whether campaigns perceive a design choice as simple as color matters for their campaign and what message they send to voters. 


# Pre-test {#sec-pre-test}

```{r}
#| label: setup-pre-test-block

# Setup
    #* modularly load functions
box::use(
    haven = haven[read_dta],
    dplyr = dplyr[mutate, case_when, select, rename],
    modelsummary = modelsummary[datasummary_skim, modelsummary],
    rstanarm = rstanarm[stan_polr, stan_glm, R2],
    tibble = tibble[tribble],
    broom = broom[tidy],
    marginaleffects = marginaleffects[marginaleffects, posteriordraws],
    ggplot2 = ggplot2[ggplot, aes, labs, theme_minimal],
    ggdist = ggdist[stat_halfeye]
)
    #* create empty data list object
data = list()
    #* import cleaned dataset 
data[['original']] = read_dta('data/pre-test/sps1.dta')

```

I conducted a pre-test in November 2019 with a sample of over 400 undergraduate students at a large university in the northwestern region of the United States. I recruited students enrolled in a political science course and were offered extra credit for their participation in the study. The study asked participants to participate in $5$ survey experiments administered by those affiliated with the university's college-level unit. These other survey experiments focus on capturing local policy issues around urban design and criminal justice and probing participants about political participation in local and national-level elections. Subjects participated in my survey experiment after one that examined their levels of political participation in local, state, and national elections.

```{r}
#| label: cleaning-block

data[['clean']] = data[['original']] |>
    mutate(
    #* female - gender of respondent
        #** gender coded as: 1 = male, 2 = female
        #** Recode to: 0 = male, 1 = female
    female = case_when(gender == 1 ~ 0, 
                        gender == 2 ~ 1),
    #* age - age of respondent
        #** age coded as: age of respondent
        #** no change
    #* white - race of respondent
        #** race: 1 = asian, 2 = African-American/Black, 3 = Hispanic/Latino, 4 = Native American, 5 = White, 6 = Other
        #** white: 0 = non-white, 1 = white
    white = ifelse(race == 5, 1, 0),
    #* pid - partisan identification
        #** combination of multiple questions
        #** pid: -3 = strong democrat, -2 = democrat, -1 = leans democratic, 0 = independent, 1 = leans republican, 2 = republican, 3 = strong republican
    pid = case_when(pid == 2 & dem1 == 1 ~ -3,
                    pid == 2 & dem1 == 2 ~ -2,
                    pid == 3 & ind1 == 2 ~ -1,
                    pid == 3 & ind1 == 3 ~ 0,
                    pid == 3 & ind1 == 1 ~ 1,
                    pid == 1 & rep1 == 2 ~ 2,
                    pid == 1 & rep1 == 1 ~ 3),
    #* blue_treatment - did they receive the blue yard sign treatment
        #** q265: 0 = did not display treatment, 1 = did display treatment
        #** new name
    blue_treatment = case_when(q265 == 1 ~ 1,
                                is.na(q265) ~ 0),
    #* red_treatment - did they receive the red yard sign treatment?
        #** q421: 0 = did not display treatment, 1 = did display treatment 
        #** new name
    red_treatment = case_when(q421 == 1 ~ 1,
                            is.na(q421) ~ 0),
    #* white_treatment - did they receive the white yard sign treatment?
        #** q423: 0 = did not display treatment, 1 = did display treatment
        #** new name
    white_treatment = case_when(q423 == 1 ~ 1, 
                                is.na(q423) ~ 0),
    #* t_party - party of fictional candidate
        #** dr_pid: 1 = republican, 2 = democrat, 3 = neither
        #** t_party: -1 = democrat, 0 = neither, 1 = republican
    t_party = case_when(dr_pid == 2 ~ -1,
                        dr_pid == 3 ~ 0,
                        dr_pid == 1 ~ 1),
    #* t_vote - vote for fictional candidate
        #** dr_info_4: 2 = do not vote for the candidate, 1 = vote for candidate & dr_info_5: 2 = do not avoid candidate, 1 = avoid candidate
        #** t_vote: -1 = avoid candidate, 0 = avoid & vote/do not avoid & do not vote, 1 = vote
    t_vote = case_when(dr_info_4 == 2 & dr_info_5 == 1 ~ -1,
                        dr_info_4 == 1 & dr_info_5 == 1 ~ 0,
                        dr_info_4 == 2 & dr_info_5 == 2 ~ 0,
                        dr_info_4 == 1 & dr_info_5 == 2 ~ 1)
  )
```

```{r}
#| label: tbl-descriptive-stats
#| tbl-cap: Descriptive Statistics

data[['clean']] |>
    select(female, white, age, pid) |>
    rename(`Female` = female, 
            `White` = white,
            `Age` = age,
            `Party ID` = pid) |>
    datasummary_skim(notes = c('Unique column includes NA values.', 'Data source: Pre-test experiment.'))
```
@tbl-descriptive-stats presents the descriptive characteristics of the sample. The sample is primarily White with over $80\%$ self-reporting that they are White(coded as: 0 = non-White, 1 = White). The sample also skews slightly female on sex, with about $60\%$ reporting that they are female (coded as 0 = Male, 1 = Female). The sample also, unsurprisingly, skews young, with the average respondent reporting an age of about 22 years old. The average respondent also appears to be an independent but leans Republican (coded as -3 = strong Democrat, -2 = Democrat, -1 = leans Democrat, 0 = Independent, 1 = leans Republican, 2 = Republican, 3 = strong Republican).

I randomly assign participants to three conditions. The conditions prompt subjects to "Imagine that [they] are driving along a road and see this yard sign" with the same message "Vote for Riley." The conditions vary on the color of the background for the image.^[The Appendix contains the images used for the treatments and the particular wording for the dependent variables.] In the control condition, the background was white. Then I had a red yard sign and a blue yard sign condition. I asked participants questions operationalized as outcomes of interest on a separate screen.

To provide a preliminary test of **$H_1$** and **$H_2$**, I ask participants to report whether the candidate was a "Republican, Democrat, or Independent." Though it does not capture pre-conscious processes, I also wanted to capture the valence the presumed out-or-co-partisan yard sign evokes for subjects. To do this, I ask respondents whether they would "seek out more information about the candidate," "avoid the candidate," "or vote for the candidate." Subjects could respond to one of three questions with a "yes" or "no" response. 

I then combine these questions into a single measure of the subject's valanced response toward the candidate. I coded those who reported they would vote for the candidate or seek more information as 1. I coded those who reported that they would avoid the candidate as -1. I coded those who reported some combination representing mixed views or some degree of ambivalence as 0.

I test whether participants presumed that the candidate was of a particular partisan persuasion based only on the color choice of the yard sign alone and whether the partisanship of the participant moderates the effect color has on valanced reactions directed toward the owner of the sign. I created two indicator variables of the treatment the subjects received: whether or not they had the blue or red yard sign treatment. The control condition is treated as the baseline condition when including both indicator variables in the model.

To examine whether subjects presumed a partisan affiliation of the fictional candidate, I fit a model using a cumulative link function from the logistic distribution and specify a prior location of $R^2$ - which represents the proportion of variance the model explains for the discretized latent variable - with an average $R^2$ of $0.3$ when the predictors are at their sample means [see @gelman_et-al_2021_cup, Chapter 15]. I assume this about the $R^2$ as I recognize that color will explain only some variation in the subject's ability to detect partisanship. However, my theory suggests that it should have a meaningful impact. Therefore, I choose an expected value of $0.3$, representing that I expect that my treatments should predict about $30\%$ of the variation. I also assume a normally distributed disturbance term with a mean of zero. I fit the model using six chains and about two-thousand iterations. I depict the results as the average marginal effects for representative values in @fig-pre-experiment-guess^[I include a table with the full results in the Supplementary Information.].

```{r}
#| label: model-block
#| eval: false
# Create empty model object
model = list()
# Models
    #** Associate color with partisanship
model[['party_guess']] = stan_polr(as.factor(t_party) ~ blue_treatment + red_treatment, data = data[['clean']], method = 'logistic', prior = R2(0.3, 'mean'), seed = 90210, chains = 6, iter = 2000, adapt_delta = 0.99, refresh = 0)
    #** evaluation of candidate
cand_eval = lm(t_vote ~ blue_treatment + red_treatment + pid + blue_treatment*pid + red_treatment*pid, data = data[['clean']])
model[['cand_eval']]= stan_polr(as.factor(t_vote) ~ blue_treatment + red_treatment + pid + blue_treatment*pid + red_treatment*pid, data = data[['clean']], prior = R2(0.3, 'mean'), seed = 90210, chains = 6, iter = 2000, adapt_delta = 0.99, refresh = 0)
# Store models
saveRDS(model, "ch_1_pre-test_models.rds")
```

```{r}
#| label: load-models

model <- readRDS('ch_1_pre-test_models.rds')
```

```{r}
#| label: fig-pre-experiment-guess
#| fig-cap:
#|  - "Associate color with partisanship"
#| fig-width: 6
associate_color = model[['party_guess']] |>
  marginaleffects() |>
  posteriordraws() |>
  mutate(
    term = case_when(term == 'blue_treatment' ~ 'Blue',
                    term == 'red_treatment' ~ 'Red')
  ) |>
  ggplot(aes(x = draw, y = term)) +
    stat_halfeye() +
    theme_minimal() +
    labs(x = "Average Marginal Effect", y = "Treatment", notes = c('Data source: Pre-test experiment.', '95% credible intervals.'))

associate_color
```

The results suggest some *preliminary* support for my expectation that individuals associate red and blue with Republicans and Democrats. My results suggest that individuals in the treatment with the red yard sign were more likely to presume that the candidate was a Republican, despite having *no* other information about the candidate other than their name and the color of their yard sign. Those in the blue yard sign treatment were more likely to assume that the candidate was a Democrat. I interpret the credible intervals for these estimates as the probability that the interval encapsulates the parameter. As neither of these intervals overlaps with zero, there is a 95% chance that the true effect is not zero. 

With confidence that the subjects associate the yard signs with the candidate's partisan affiliation, I turn my focus to their evaluations of the owner of the yard sign. I make the same assumptions with the model of candidate evaluations given the treatment. As the outcome of interest is an ordinal categorical variable, I specify a cumulative link function from the logistic distribution and specify a prior location of the $R^2$ with an average of $0.3$ when the predictors are at their sample means. I include the model results in the second column of the results in the Supplementary Information and as the conditional marginal effects of representative values in @fig-pre-experiment-cand-eval.

```{r}
#| label: fig-pre-experiment-cand-eval
#| layout-nrow: 2
#| fig-cap: "Effect of yard sign color on candidate evaluation"
#| fig-subcap:
#|  - "Republicans would vote for candidate with Red yard sign"
#|  - "No difference among partisans in support for candidate with Blue yard sign"
#| fig-width: 6
evaluation_candidate_red = model[['cand_eval']] |>
  marginaleffects::plot_cme(effect = 'red_treatment', condition = 'pid') +
    theme_minimal() +
    labs(y = 'CME of Red treatment on candidate evaluation', x = 'Party ID')
evaluation_candidate_blue = model[['cand_eval']] |>
  marginaleffects::plot_cme(effect = 'blue_treatment', condition = 'pid') +
    theme_minimal() +
    labs(y = 'CME of Blue treatment on candidate evaluation', x = 'Party ID', notes = c('Data source: Pre-test experiment.', '95% credible intervals.'))

evaluation_candidate_red
evaluation_candidate_blue
```

@fig-pre-experiment-cand-eval presents results suggesting that among Republicans receiving the red treatment, they are more likely to indicate a positive valence toward the candidate than Democrats, who are more likely to report a negative evaluation of the candidate. While Democrats receiving the blue treatment are more likely to report a positive valence toward the candidate relative to Republicans, the effect is plausibly zero. This may be an artifact of asymmetric political polarization. Some scholars suggest that Republicans are much more group-oriented than Democrats [see @lupton_et-al_2020_bjps]; these results may fit with such a narrative. Republicans are reactive to those they may presume to be co-partisan in a way that Democrats do not appear to be as reactive in a similar magnitude.

The evidence from this pre-test is limited. The experimental design is not testing pre-conscious evaluations. The treatments are explicitly political and rely upon a convenience sample of those enrolled in political science classes. The ability of individuals to associate partisanship with the treatments is likely overstated. The sample is also quite unrepresentative, so the inference is indeed threatened. As I discussed with the third model, I also have omitted variable bias as the result of my outcome is a better measure of approach behaviors for those who are extroverted. 

Though there are problems with the design here, it does serve some purpose for this prospectus. It demonstrates that despite its problems, color can betray information at some level when thinking of politics. It also provides a functional first test of a possible research design to examine what this particular design can and cannot tell me about my proposed mechanism. 

# Discussion

Not only do yard signs matter for electoral strategy, outcomes, and voter attitudes and perceptions, but I suspect that the yard signs' color partially explains these phenomena.

While yard signs are a simple form of party branding, richer theorizing about how diverse types of potentially politically-relevant information allows us to fill some of these gaps. In the case of yard signs, while some may be skeptical of whether yard signs and campaigns, more generally, matter for electoral outcomes, an application of the snap-judgment model on yard signs suggests that they indeed have potential and provide an explanation as to how it occurs.

Outside of color on yard signs, I suspect that color provides valuable information that is processed efficiently by the public. Due to this, voters can connect colors like Red and Blue to make assumptions about a political candidate's partisan affiliation. With this information, voters can then evaluate the candidate. This is a much simpler task than hearing the candidate's positions on immigration, for example, and then making a connection to their partisan affiliation.