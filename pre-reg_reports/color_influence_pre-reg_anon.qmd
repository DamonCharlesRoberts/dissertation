---
title: |
  How do colors convey political information and effect individual attitudes?
repo: |
  For replication, go to: <https://github.com/DamonCharlesRoberts/dissertation>.
author:
  - name: Damon C. Roberts
    email: damon.roberts-1@colorado.edu
    orcid: 0000-0002-4360-3675
    title: PhD Candidate
    affiliations:
      - id: CU
        name: University of Colorado Boulder
        department: Political Science
        address: 333 UCB
        city: Boulder
        region: CO 
        postal-code: 80309-0333
abstract: |
  Are colors important to politics as a form of political information? In this project I argue that they are. Building upon existing theories of political information processing and common theories of information processing, attitude formation, and affect in neuroscience, I present a snap-judgement model of political information processing. In this model, colors provide automatic information about a politically-relevant object that may shape subsequent processing of more complex information that the political science literature is more familiar with. The model has important implications for how we consider the role that visual information has on political information processing and attitude formation. The model additionally provides clarity on motivations behind party branding and the ways in which information may activate partisan biases pre-consciously.
nonblind: blind
bibliography: "../assets/references.bib"
format:
  pdf:
    template: "../../../templates/manuscripts/apsr_template.tex"
    cite-method: biblatex
execute:
  echo: false
  warning: false
  message: false
params:
  os: windows
---

```{python}
#| label: setup-block
# import modules
    #* from environment
import os # for path management
import sys # for path management
import numpy as np # for array management
#import polars as pl # for dataframe management
import cv2 # for color detection
import matplotlib
from matplotlib import pyplot as plt # for graphics
from matplotlib import image as mpimg # for displaying images
from IPython.display import display, Markdown # for displaying inline code
    #* user-defined
sys.path.append("../code/")
from fun import colorDetector
```

# Introduction

Are colors important to politics? This project argues that they are; at least that they convey information that voters and campaigns care about. People rely on more information than just purely political information to understand politics [@pietraszewski_et-al_2015_c]. To reduce cognitive load, the affiliation detection system allows for efficient prediction of social behavior through the use of associating various cues with a group. In politics, associating Black voters with the Democratic party and White voters with the Republican party is one such example [@pietraszewski_et-al_2015_c]. As the colors red and blue are consistently linked with the Republican and Democratic parties [@elving_2014_npr], respectively, we should explore whether color acts as an affiliative cue for individuals in politics.

Existing theories of political information processing have yet to examine visual information, more broadly. Color as a simple, but yet ubiquitous, piece of visual information may have more influence over shaping political views than we give it credit. As visual information is processed automatically and faster than other forms of information [see @ames_et-al_2012_ohsn], I argue that it triggers associated neurological pathways that shape the subsequent information processing of the more traditionally considered types of political information.

I propose two studies to test these claims. Yard signs are a simple, but yet effective source of campaign branding for political candidates. They shape the attitudes of those who view them [@makse_et-al_2019_oup] and they can even aggregatively shape electoral outcomes [@green_et-al_2016_es]. As yard signs are a simple and static form of campaign advertising, they are unable to rely heavily on more complicated forms of information. One form of information they rely on and vary significantly on is color. In [Study 1](#sec-study-1), I propose an experiment that examines whether the public notice and whether their attitudes are shaped by "Republican Red" and "Democratic Blue" on the yard signs of a fictional candidate. In [Study 2](#sec-study-2), I examine whether campaigns percieve that the color on a yard sign has real world effects on the perceptions of the candidate by voters. I do this by first examining the ways in which electoral context shape variation in the use of these partisan colors. Second, I have informal interviews with campaign staff to determine what shapes the decisions about what colors to include on a campaigns yard sign.

I then present a pre-test which experimentally tests whether yard signs using "Republican Red", "Democrat Blue", and White lead to different perceptions of the candidate's political views. I find that a fictional candidate with a background of the "Republican Red" are percieved to be more Republican and the fictional candidate with a background of "Democrat Blue" are perceived to be more Democratic. I also find that Republican voters are more likely to report a willingness to vote for the candidate with "Republican Red" on the yard sign and Democratic voters are more likely to vote for the candidate with the "Democrat Blue" on the yard sign.

# The role of visual information in politics

As the rise of television consumption necessitated a change in the focus of the medium in the research for political communication scholars [@hall-jamieson_2014_ohpc], so too does the rise of image-based social media. For a number of methodological and disciplinary reasons, the visual aspects of television were not of much focus in the literature [@bucy_joo_2021_ijpp]. However, with the trend towards ubiquitous use of the public to use image-dominant social media platforms like TikTok and Instagram, news organizations and politicians have responded and are relatively active on these platforms as well. In response, we, as scholars, need to make this transition to integrate the role of simple visual information into our theories of political information processing (abbreviated as *pip*) and attitude formation. 

A number of scholars make this same argument. An edited issue of *The International Journal of Press/Politics* is centered around making the point that visual politics is understudied; yet important [@lilleker_2019_pm]. Those who are engaged in these sorts of question attribute these challenges to methodological and the requirement for the difficult task of interdisciplinary theorizing to engage in such questions [@gerodimos_2019_pm;@bucy_joo_2021_ijpp]. 

How does politically-relevant visual information matter to politics? From a evolutionary-biological perspective, visual information is a common source of information for millions of years that a variety of single-and-multi-cell organisms rely upon to evaluate their environment [see @grabe_bucy_2009_oup, Chapter 1 for a useful discussion]. Visual information processing, as an ancient biological invention, the human brain is organized around the processing of it. Reflecting this, many scholars of neuroscience argue visual information to be the fastest form of information processing for humans. For example, even complex visual information such as the warmth expressed in someone's facial features are automatically and subconsciously processed in only about 33`ms` [@ames_et-al_2012_ohsn].

Approached from a different perspective, as humans are cognitive misers \index{cognitive misers}, visual information in the realm of politics provides efficient information to voters about politically-relevant actors and events [@lilleker_2019_pm]. Evidence suggests that voters rely on simple visual information in the background of an image to infer the ideological position [@dan_arendt_2021_ijpp] and that their coverage reflects electability perceptions [@stewart_et-al_2021_ijpp] -- which influences reported desire to vote for the candidate. Images posted on social media by politicians provide more personalized information about them and that they take on their own styles [@lindholm_et-al_2021_ijpp; @peng_2021_ijpp]; reflecting that it is an alternative source of information curated to attract support. There is evidence to suggest that even simple party branding on yard signs have an emotional appeal and encourage a shift in attitudes toward the person who owns the yard sign [@makse_et-al_2019_oup]. That is, even branding as simple as yard signs appear to influence attitudes of those who view them. However, like all types of party branding, there remains questions about the contribution that the individual might visual components provide.

While visual politics is enjoying more attention by social scientists, there is still little focus on the simplest visual information: color. In the context of the United States, the "Republican red" and "Democratic blue" are a relatively recent invention that likely has significant import in a era of significant effort by the parties to distinguish themselves from each other [@clifford_2020_pb] and where voters toe the party line [@utych_2020_es]. Since the 2000 presidential election, the media have consistently used the color red on their electoral maps in "horserace" journalism to represent Republicans and blue to represent Democrats [@elving_2014_npr]. The supposed consequence of this is that Democrats now report preference for the color blue over the color red; and Republicans report a preference for the color red over the color blue [@schloss_palmer_2014_pbr]. Beyond this however, we have yet to robustly develop and test theories about the broader impacts that color has on political information processing and attitude formation.

As the broader field of study of visual politics is under-theorized, theorizing about the use of color as a form of information is also quite limited -- perhaps even more so. The literature that does exist argues that colors are a source of visual information to classify more abstract concepts for voters. For example, in western Europe, voters are better at connecting the ideological positioning of a party with the color they use in their branding, the longer-surviving and more prominent the party is [@casiraghi_et-al_2022_pp]. The use of politically-relevant colors activate biases toward pre-existing ideological and partisan preferences among voters in a Spanish sample [@maestre_medero_2022_pr]. It remains unclear, however, what the particular psychological mechanism drives this, and how even colors as a form of political information, is organized into a schema that allow voters to quickly access to form political attitudes or how they moderate the effects of other types of political information on attitude formation. As a jumping-off point, we can turn to the literature on political information processing (heretofore abbreviated as *pip*)\index{political information processing}. 

The first prominent model of *pip* is derived from rational choice perspectives. The memory-based model of *pip* views attitudes as a weighted collection of prior information [see @zaller_1992_cup]. As individuals receive new information, they organize it into a schema that is relative to prior objects they already have encoded. With the encoding of this new information, the model predicts that individuals incorporate this new object with similar objects to form an attitude. This schema then may be more accessible in similar contexts and may then sample from its elements when prompted to express a political attitude. While the Receive-Accept-Sample (RAS) model accepts the view that expressed attitudes are based on a weighting that is most accessible at the time of attitude expression [@zaller_feldman_1992_ajps], it still presupposes that the weighting is an average of prior information.

The second prominent model challenges this latter point. The online model of *pip* contends that individuals do not evenly weigh information, but that whether they even store it into their long-term memory to access later is biased in the direction of supporting pre-existing attitudes [@lodge_taber_2013_cup]; this phenomenon is referred to as motivated reasoning by the psychology literature [@kunda_1990_pb]. This model suggests that people ignore new information that goes against their prior beliefs and that information confirmatory of their preferences are quicker to access -- referred to as hot cognition [@lodge_taber_2013_cup].

The online model conceptualizes this underlying mechanism of information encoding and attitude retrieval as automatic [@lodge_taber_2013_cup]. This occurs as a result of the information's strong associations with valanced appraisals of the information guiding the attitude [@lodge_taber_2013_cup]. This brings political scientists closer to the dominant conceptualizations among neuroscientists and psychologists concerned with memory retrieval, encoding, and attitude formation [see @fazio_2007_sc]. Namely, that memories are encoded and retrieved based on associations and are quickly done so as a result of their association with valanced appraisals [@kensinger_fields_2022_ohhum]. What remains unexplored is how visual information such as color may prime individuals to engage in motivated reasoning subconsciously, and if they do keep their attention on the object, what paths are activated by such information.


# Integrating color into a model of political information processing

Existing models of *pip* are largely focused on complex forms of political information such as text. As individuals process visual information before other sorts of information, we might expect that they may form the snap-judgement or the initial appraisal of an object. This has a number of important implications; from suggesting that our theories of *pip* should be broadened to reconsider what constitutes politically-relevant information to what it means for our substantive understanding of how people process political information and the calculus involved in political attitude formation.

Though the online model of information processing goes a long way to inform us about the ways that our physiology engages attitude formation and retrieval, the types of information it considers necessarily limits the applicability of the theory to other forms of political information. Color and other forms of simple visual information are processed much more quickly and occurs more frequently than text-based information [@mehta_zhu_2009_s]. As color and other types of visual information are processed differently, we should consider its use as political information differently as well. As visual information is affectively encoded [@cimbalo_et-al_1978_jgp], this means that it has the potential to effect the affective state and processing of more complex information, such as text. That is, the visual information provides a snap-judgement or an impression of the object through faster processing and activates particular neurological processes that influence subsequent information appraisals [@ames_et-al_2012_ohsn]. This implies that the conclusions drawn from such *pip* models may be systematically biased without considering the upstream effects of non-text information; such as simple visual information like color.

Before expanding upon the role that colors have on shaping political attitudes, let me first define an attitude as a concept. An attitude represents an accessible, valanced, evaluation of associated prior information and experiences. This conceptualization fits with that of the Object-Evaluation Associations Model [@fazio_2007_sc]. As opposed to viewing attitudes as a latent collection of memories, as is done in the memory-based model of *pip* [@zaller_feldman_1992_ajps], it views attitudes as measurable evaluations of memories. As memories, are at the core of an attitude, the association of memories with its evaluative component [see @kensinger_fields_2022_ohhum] contribute to the perspective that attitudes are affective. What this implies, is that we should be able to measure attitudes but that such an operationalization requires a careful consideration of the role that the context plays on any given measure of an attitude as they are resulting from memories [@fazio_2007_sc].

In line with the existing models of *pip*, I conceptualize attitudes as associative. This means that attitudes may be unstable - not stochastically, though. As attitudes are associative, they manifest slightly different depending on the associative paths that are activated [@fazio_2007_sc]. The retrieval of relevant memories to the attitude depend on a number of factors such as the recency of the event, the similarity of the context, and the importance or salience of the memory [@kahana_et-al_2022_ohhum]. This means that the memories that are retrieved to contribute to an attitude are quite variable. However, to understand where that variability comes from, we must understand the deeper processes that influence the way information is encoded and later retrieved. This illustrates my point of the need to further develop the reigning models of *pip*. Colors may act as one such contextual feature that may lead to this variability in how a given set of political information may shape attitudes.

Colors are associative and are affectively encoded [@cimbalo_et-al_1978_jgp]. When individuals access a memory, they do not just recall an object but they may recall visual information such as the color of an object. As visual information like colors are quickly processed and encoded, they are also quickly retrieved with their associative memories and can do so unconsciously [@mehta_zhu_2009_s]. As they are affectively encoded, their associations with particular memory contribute to the evaluative component of the memory. For example, colors like red are associated with anger, arousal [@valdez_mehrabian_1994]; whereas blue is associated with things like happiness and pleasure [@dandrade_egan_1974_ae]. What this means is that colors are particularly powerful as contextual information shaping the subsequent processing and integration of "traditional" forms of political information to construct an attitude. As the preference for a particular color correlates with political attitudes [@schloss_palmer_2014_pbr], they may have some causal influence upon political attitudes; rather than just a correlation with them.

According to the literature in affective neuroscience, visual information is processed in parts of the brain such as the visual cortex [@goldstein_brockmole_2017_cl]. This will activate other areas of the brain and will make associated paths "hot". One such area is the amygdala. Neuroscientists believe that as visual information is quickly and subconsciously processed, the amygdala takes such information and appraises the information based on the paths it activated; this generates a simple affective response to such information [@winkielman_et-al_2011_ohsn]. More complex, categorical, emotion occurs later in conscious processing [@winkielman_et-al_2011_ohsn]. This means that once politically-relevant visual information is detected, this information is passed from the retina to the brain. Once there, the brain attempts to classify the visual information by activating networks of neurons that are associated with the current information. With these activated pathways, the brain also attempts to appraise such information based on the quick classification. As memories are affectively encoded [@kensinger_fields_2022_ohhum], these memories help areas such as the amygdala to appraise the current information.

The automatic and subconscious appraisals of the visual information one encounters encourages particular behavioral and attitudinal motivations [@valentino_et-al_2011_jop;@ralph_anderson_2018_pup]. This has evolutionary roots for the purposes of survival [@ralph_anderson_2018_pup;@parker_2003_p]. While emotional appraisals can lead to complex motivations such as anxiety leading to motivations for information seeking [@marcus_2000_arps], affective appraisals are valanced and are more automatic [@winkielman_et-al_2011_ohsn]. These affective appraisals lead to a desire to either retract or engage more with the object [@valentino_et-al_2011_jop]. We should expect then, that the snap-judgement resulting from automatic processing of politically relevant visual information will lead to an affective response that motivates either a desire to engage more with the object or to disengage. 

While the visual information may encourage a particular immediate reaction to engage or disengage from the information, subsequent information processing and more conscious processing adjusts this initial appraisal generated by the snap-judgement [@kensinger_fields_2022_ohhum]. While subsequent information may amend one's snap-judgement, the snap-judgement nevertheless influences the processing of subsequent information by activating particular paths which is later encoded as associated with the object as it is converted to a memory [@lodge_taber_2013_cup;@kensinger_fields_2022_ohhum].  

@fig-snap-judgement-model-chapter presents an illustration of the snap-judgement model.

```{mermaid}
%%| label: fig-snap-judgement-model-chapter
%%| fig-cap: Snap-judgement model
%%| fig-width: 6
%%{init: {'theme':'base', 'themeVariables':{'primaryColor':'#ffffff', 'primaryBorderColor': '#000000'}}}%%

graph TD
    A[Detection of politically-relevant visual information] --> B(Activation of retrieval mechanism)
    B --> C[Memory and contiguous paths hot]
    C --> D[Appraisal of hot autonomous nervous system]
    D --> E1[Negative Valence]
    D --> E2[Positive Valence]
    E1 --> F1[Disengagement motivation]
    E2 --> F2[Attention activated]
    F1 --> |Neg. new information| G1[Encoded as negative]
    F1 --> |Pos. new information| G2[Encoded as positive]
    F2 --> |Neg. new information| G3[Encoded as negative]
    F2 --> |Pos. new information| G4[Encoded as positive]
    G1 --> H1[Strengthens negative path]
    G2 --> H2[Weakens negative path]
    G3 --> H3[Weakens positive path]
    G4 --> H4[Strengthens positive path]
    G2 --> |forgotten| H1
    H2 --> |reinforced| G2
    H3 --> |reinforced| G3
    G3 --> |forgotten| H4

```

What all of this means for *pip*, is that when we view political events or consume political information that has a visual component, we are going to encode visual information along with it. Taking expectations formed from theories of motivated reasoning [see @kunda_1990_pb], I'd expect that the visual information that we encode with it is likely congruent with the evaluation of the object; we are likely to be unwilling to encode the visual information that is not congruent with the visual information as we do with text-based political information [see @lodge_taber_2013_cup]. That is because unconsciously, we are going to experience a motivation to disengage from such information as soon as we appraise the visual aspects of an object as incongruent with existing attitudes and therefore to be uncomfortable. It should also influence how we retrieve memories when we are encountered with new information as well. This will have an effect on the attitudes that we express as a result. Additionally, this predicts that we will spend less time processing, accessing, and encoding congruent information [@lodge_taber_2013_cup].

Let me illustrate the snap-judgement model with a common experience for residents of the United States. Say you are driving down a highway. At 65 miles an hour, you are traveling at about 95 feet per second at this speed. Your attention is split. Your eyes are focused on the conditions of the road in front of you, on the cars in front of you, and on the rear-view mirror where your kids are either dropping food in the crevice between the seat or are trying to grab your attention. Out of the corner of your eye, you see a sign. It is not a road sign, because it is not on the familiar white or yellow background with black lettering. It's election season. You correctly infer that it is a political yard sign. In this split second, you notice the color of the sign and may see a name: Mitch McConnell. You now are racking your brain to think about who that is. If you are politically engaged, you might come to that recognition of the name quickly or it may take you quite a bit longer if you are less politically engaged [see @kahana_et-al_2022_ohhum]. You figure out that they are a Republican politician. You may have come to this with help by the fact that every year you've seen yard signs on this stretch of highway; and you know that when you see those electoral maps pop up on your news app on your phone that the electoral forecasts always represent Republican support with red and blue for Democrats. Once you've figured out who this person is, with the help of this other information, you have a reaction: "ugh, that guy is too loyal to Trump" or "yeah! He's loyal to Trump". You've expressed a political attitude.

What the snap-judgement model predicts is happening in your head is that as soon as the light that bounces of the sign to produce a particular wavelength hits your eyes, your brain is already trying to make sense of this information. This is a useful tool for survival that biology has optimized for millions of years [@parker_2003_p]. Rather than processing the visual information slowly and you find yourself already in the jaws of a predator or to process it quickly but form the wrong impression and run away from a friend, the brain processes the information quickly and subconsciously [@newell_1990_hup]. To make sense of such information, it accesses information that is familiar and similar to what it is currently attempting to process for efficiency [@kahana_et-al_2022_ohhum]. This is accessing memories and contains valanced information [@kensinger_fields_2022_ohhum]: should I avoid this or is it pleasant? Once the brain has finished such processing, it can pass along its prediction to your conscious memory. Once a reflex of avoid or approach is made, this opens up space for your brain to process the more difficult information: to take the patterns of the light as shapes that construct symbols and letters. This comes later because this information not only requires access to information about what it *is*, but also what it *means*; and once you understand what it means, then you have the information necessary to evaluate it. 

The snap-judgement model predicts that you first process the colors of the yard sign. You access associative memory to figure out what those particular wavelengths represent: red, white, blue? As these colors are associated with different emotional states [see @cimbalo_et-al_1978_jgp] and the resulting behavioral consequences, your brain starts sending signals to the rest of your body to prepare it to react [see @sander_2013_chhan;@dror_2017_er]. You now need to figure out what the rest of that information was. What were the patterns of that light? It appears that there were some white letters on the sign. There was an "E", a "L", an "E", a "C", a "T". That creates the word "ELECT". Meaning to vote for. There were some more letters on the sign: a "M", an "I", a "T", a "C", a "H". A name. The full name is "Mitch McConnell". Since it is about politics, it must be a politician named Mitch McConnell. Now imagine, the information was the same, except the color was blue. You may take more time to figure out how that Mitch McConnell person is and come to your reaction to seeing their yard sign. This is because without the color red, you first are thinking about Democrats who are named Mitch McConnell, only when you come up empty on your mental rolodex, you figure out that it is the Republican Mitch McConnell.

How do you react to the color and then to the name? Social groupings are not simply abstract concepts invented by social psychologists. They are also reflected in our neurobiology. For example, researchers find activation of parts of the brain such as the anterior insula when we see someone in our social group outperformed by someone from the out-group [see @zink_barter_2012_ohsn]. The anterior insula activity is associated with physical and emotional pain; not just for ourselves but also for others [@adolphs_janowski_2011_ohsn]. Others have also observed that when seeing someone part of a high-status social group, that there is an increase in activity in the sensorimotor cortex and supplementary motor area indicating more activity in the areas of the brain that encourage movement [@zink_et-al_2008_n]. Visual information of someone in your social group speeds up processing, is more salient, and demands more attention than visual information of an object outside of your social group [@zink_barter_2012_ohsn].

There is significant evidence in support of the theory that our partisan identification reflects more than just our attitudes about politics, but that it is a social identity [see @campbell_et-al_1960_jws; @mason_2018_cup] that guides our attitudes [see @achen_bartels_2016_pup; @white_et-al_2014_apsr; also @bullock_2011_apsr]. As our political attitudes reflect shared views among co-partisans [@pickup_et-al_2020_pb], our reactions to such political information contains influence by the congruency to which that political information aligns with our partisan identification. This means that the visual information we glean from politics is likely to motivate those neurological features of social groups and will explain resulting behavioral manifestations reacting to such information. That information is also likely to be processed at different rates as well. That is, while visual information carries affective associations that are quite general, we should also expect that politically-relevant colors and visual information are associated to the structures represented by our partisan identification.

From this discussion, I expect the following: that individuals do pay attention to the colors used in campaign branding (***$H_{1}$***); that these colors that they notice shape perceptions about the person and ideological symbol represented in the branding -- meaning that they express different levels of preference for receiving more information that is similar to what they saw and their levels of preference for supporting such a campaign (***$H_{2}$***); that more positive perceptions are explained by the consistency of information -- simple visual information with more complex "traditional" information (***$H_{3}$***); this positive and consistent information is processed quicker than negative and inconsistent, negative and consistent, and positive and inconsistent information (***$H_{4}$***); and finally that campaigns make strategic choices about their branding to attract voters (***$H_{5}$***) in line with their primary objective of reelection [@fenno_1973_lb;@mayhew_1974_yup].

# Study 1 {#sec-study-1}

The purpose of [Study 1](#sec-study-1) is to examine the effects of color in a common form of campagin branding -- yard signs -- on the attitudes of the observer. Evidence suggests that yard signs *do* matter for shaping political attitudes [@makse_et-al_2019_oup], vote intentions [@makse_et-al_2019_oup], and even electoral outcomes[@green_et-al_2016_es]. As they are quite simple, cheap, intrusive, and common forms of campaign branding, they provide a conservative test of the effects of color in campaign branding. Using yard signs in this study, I test the first 4 hypotheses I derive from the snap-judgement model. First, [Study 1](#sec-study-1) tests the claim that individuals do indeed notice color on electoral yard signs. Next it tests the claim that these colors that individuals detect influence the viewer's evaluations of the yard sign and candidate represented on it. [Study 1](#sec-study-1) then tests the claim that the effects on perception are moderated by how consistent the color is with the more complex information displayed on the yard sign. And finally, [Study 1](#sec-study-1) then examines whether positive information that contains consistency is processed quicker than negative or inconsistent information. That is, do partisans quickly detect and encode information from a clearly co-partisan political candidate?

## Design

I recruit 1,000 participants from Prolific.^[Participants are paid at a rate of $12.00 per hour. On top of the price per participant, Prolific charges a 30% servicing fee and an additional fee to guarantee a nationally representative sample.] After providing informed consent to participate in the study, participants are redirected to Pavlovia^[Pavolovia allows for researchers to host and run open source experiments for about $0.20 per participant (to cover their server costs). I use it primarily for the purposes of integrating the JavaScript components for my experimental design.] and are provided with a demographics and political attitudes questionnaire. This questionnaire includes common questions about the participant's ascriptive and descriptive characteristics along with questions about the participant's political ideology, partisan identification, interest in politics, and political knowledge.

I include those questions in the questionnaire due to expectations that they may act as confounds in my hypotheses. As political knowledge is deeply intertwined with the strength to which an individual identifies with a political party [@delli-carpini_keeter_1996_yup], I expect that political knowledge is an important confounder in my tests of $H_2$, $H_3$, and $H_4$. Therefore, I include a common battery for assessing political knowledge. As political knowledge is shaped by levels of interest in politics as well [@delli-carpini_keeter_1996_yup], I include the common question to assess levels of self-reported interest in politics. I additionally include a number questions collecting information on participants' ascriptive and descriptive characteristics such as age, education, gender identity, and racial identity as a number of these are correlates with partisan identification [see @campbell_et-al_1960_jws;@mason_2018_cup]. Additionally, I include a question about the respondent's sex assigned at birth and about whether they have received a diagnosis of any type of color blindness. As some individuals may possess undiagnosed colorblindness, asking about their sex assists in covariate balance. I additionally include four open-ended question asking participants to describe (1) their "first memory of a political event", (2) "what occurred in the most recent political event" they encountered, (3) how they "keep up-to-date with current political events", and (4) "what occurred in the most recent non-political event" they encountered. The use of multiple open-ended questions help with providing an attention check along with identifying duplicated responses for those that may be spoofing IP addresses with the use of a VPN [@kennedy_et-al_2021_poq].

I then present participants with an instruction screen informing them of the task for the experiment. In the first trial of the experiment, participants are randomly presented with two of three possible yard signs; one at a time. These yard signs are simple with the text "Vote for Riley" and a solid background color of either "Republican Red", "Democratic Blue", or White.^[See the supplementary information to view all of the stimuli used in [Study 1](#sec-study-1).] There is an added component to this, however.

Rather than use eye-tracking devices and software, I instead use Mouseview.js [see @anwyl-irvine_et-al_2022_brm] which either blocks out or blurs a large portion of the participant's screen and encourages them to move their mouse to view different parts of the screen in isolation. As the participants move their cursor around the screen, it tracks the coordinates of the cursor along with the "dwell" time of the cursor in that particular coordinate. One primary benefit of Mouseview.js is that it allows for researchers to field their experiments outside of a lab-based setting -- while providing results that are robustly correlated with the results from a design employing eyetracking [@anwyl-irvine_et-al_2022_brm]. This opens up the flexibility for researchers to rely less on convenience samples; which are common with eye-tracking studies. For my design in particular, I am concerned about reliance on a convenience sample due to variation in participants' ability to detect and process color in the U.S. population relative to a student sample. This means that Mouseview.js is a particularly useful tool for my study. A published pilot version of the experiment used in [Study 1](#sec-study-1) is published on [Pavlovia](https://run.pavlovia.org/damoncroberts/diss_ch_1_pre-reg/?__pilotToken=c74d97b01eae257e44aa9d5bade97baf&__oauthToken=9a645f267f9b83c8ebb48e60093bae5a746da56a6c824b8343389a9329fa2365).

When viewing each of the yard signs in the first trial, there is a blur over a substantial portion of the screen. At any given point in time, participants can view only 8% of the image without an obstruction; which simulates the observation that we typically foveate on about 8% of our available visual field at any given time [@wedel_pieters]. Participants move their cursor to explore the yard sign and are given 5000 ms to do so until the image goes away to encourage a consistent and short duration to explore the image.^[In marketing research, some studies give participants about 6000 milliseconds in eye-tracking studies to examine a brand and to formulate an intention to purchase a product or not [@wedel_pieters]. With Mouseview.js, a study examining the tool's correlation with optical responses to viewing disgust-and-pleasure-evoking images uses 10000 milliseconds; but is intended to be an extended amount of time [@anwyl-irvine_et-al_2022_brm].] After exploring each image, participants are asked what colors were on the yard sign and whether they felt that the candidate represented on the yard sign was a Democrat, a Republican, or Neither. After viewing both images, they are then asked to indicate their preference among the two images. To ensure that participants have a standardized initial placement of their cursor, prior to viewing the yard sign, I display a blank page that requires participants to click a "Next" button . Immediately after clicking "Next", participants are then shown the yard sign. The goal of this is to ensure that variation in where participants go to explore the image is not dependent on a non-standard starting point for their cursor. I additionally utilize a gaussian blur for the overlay of the image rather than a solid overlay obstructing the participant's view. This gaussian blur allows participants to see a very blurred visual field beyond the cursor. This allows participants to see enough to take purposeful action to explore blurred parts of the image that attract them [@anwyl-irvine_et-al_2022_brm].

There are three more trials that are much like the first trial. What is different between the two other trials is that I vary the amount of color that are on the yard signs (trials 2 and 3) and I provide more textual information that deviates from the association of Republicans with red and Democrats with blue (trial 4).

## Do individuals notice color in political branding?

To address this first question, I use two measures of a participant's attention toward the colors on the yard sign. The first measure is collected through a question posed to the participant after viewing each yard sign, "what color was the yard sign?". The second measure is more implicit: it is an accounting of the time someone's mouse hovered over the non-text elements of the yard sign relative to how long their mouse hovered over the text. The self-reported measure allows us to examine the conscious detection of color while the more implicit measure allows us to examine where individuals' attention goes: toward the color or toward the text.

This is largely a descriptive exercise. I intend to compare the differences in measures between the "non-partisan" (white) yard sign and the partisan (red and blue) yard signs. I additionally intend to examine the differences in measures between the partisan yard signs among self-identified partisan respondents.

## Do colors shape perceptions of political objects?

To address the next question of whether the colors effect perceptions of the candidate and the yard sign, I ask participants to report whether they percieved the candidate to be a partisan -- either Republican or Democrat, or as a non-partisan. Everything on the yard signs remain constant except for the color. As representations of ideology are associated with more than just political views but things like space [@mills_et-al_2016_bbr] and color [@maestre_medero_2022_pr], differences between respondents on the percieved political affiliations of the candidate should be more than stochastic differences, but should be based on the associations with the colors red and blue with partisanship and the lack of political information that the color white conveys.

I examine differences in the reported perceptions of the candidate's partisan affilation among respondents. As respondents see multiple yard signs, I intend to calculate the Individual Marginal Component Effect (IMCE) which allows me to view the within individual difference [@zhirkov_2022_pa] in perceptions with varying color-based information among the yard signs they view. I also am able to calculate the Average Marginal Component Effect (AMCE) by examining the average difference in perceptions among subgroups that vary on level of political interest, partisan strength, and level of political knowledge. 

## Do these perceptions require consistency between information types?

Another hypothesis derived from the snap-judgement model suggests that inconsistency in the visual information that the yard sign presents will lead to more mixed perceptions of the candidate's political stances. The latter trials of the study are designed to present yard signs with mixtures of non-partisan and out-partisan colors. For example: presumably Republican yard signs that are mostly red, but has some blue or white in it.

I take the same analytical strategy to address this question as I did before. I estimate the IMCE and AMCE's among respondents. I should expect that for the trials that use less "consistent" visual information demonstrate more ambivalence among respondents in their reported perceptions of the politician's positions. Specifically, I expect that the yard signs that have both red and blue on it will be percieved as more moderate and that the higher proportion of the color red or blue among the two colors will lead respondents, on average, to be more likely to believe that the candidate leans more Republican or Democratic.

## Do partisans process co-partisan branding faster?

The other analytical tasks do not examine expectations derived from the motivated reasoning portion of the model. That is, do people process in-group information faster than out-group information? There is evidence of these tendencies in political circumstances [@lodge_taber_2013_cup]. 

To examine whether motivated reasoning is also active with the processing of politically-relevant color, I examine the difference between the amount of time between the start of viewing a stimulus and clicking "Next" to stop viewing the stimulus among those who were viewing a presumed co-partisan yard sign relative to those viewing a presumed out-partisan yard sign. As motivated reasoning tends to be more prevalent among strong partisans and those highly knowledgeable and interested in politics [@lodge_taber_2013_cup], I control for responses to the pre-treatment knowledge, interest, and partisan strength batteries.

# Study 2 {#sec-study-2}

[Study 1](#sec-study-1) presents evidence in support of the snap-judgement model in a relatively artificial way. The yard signs presented as stimuli are extremely simple in information content and design. Furthermore, the actual viewing of yard signs in real world scenarios does not occur through a computer screen with an overlay allowing individuals to observe only a fraction of the screen at a time. 

One way to examine the real world effects of color on decisions about campaign branding is to go directly to the experts. If the effects of [Study 1](#sec-study-1) hold up in real world conditions, we should expect that campaigns do not include the same design elements across electoral contexts. That is, if the color of a yard sign does indeed matter and its electoral effects are dependent on the perceptions of potential voters, we should expect that campaigns are less likely to place yard signs with a large amount of Red or Blue. for example, in districts that contain relatively few co-partisans.

## Do branding choices reflect electoral context?

```{python}
#| label: some-script-execution
#| eval: false
import os
os.system('../../code/03_capd_downloading_images.py')
os.system('../../code/04_mit_election_lab_merge.py')
os.system('../../code/05_color_detection.py')
```

To examine whether the use of colors on yard signs vary in systematic ways depending on electoral context, I collect images from the 2018, 2020, and 2022 Congressional elections for the House of Representatives across the United States. These yard signs are pulled together on one website by the Center for American Politics and Design^[See: https://www.politicsanddesign.com/]. From this website, I am able to extract over 1,100 images for these three elections. I then combine this information with district-level data provided by the MIT election lab on election returns for candidates in these House elections ^[See: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IG0UN2].

With these data, I detect the percentage of the "Republican Red" and "Democratic Blue" on the yard signs and examine whether the 5-year smooth moving average of Democratic candidate vote share in that given district correlate. The purpose of this analysis is to examine the hypothesis that campaigns respond to the preferences of partisan voters and adjust their branding as a result. In this case, the branding being the color on the yard sign.

To provide an example of how the color detection works, I collected the GOP logo used on their official Twitter account during the 2022 midterm election cycle. I load this image and convert it to a three-dimensional array that contains information about the GBR (reversed RBG) values for the pixels in that image. I then resize the images to be a standardized 224 $x$ 224 pixels. The computer is trained to detect a range of GBR values that encompass the official "Republican Red"^[lower values: (93, 9, 12), higher values: (236, 69, 75)]. For the broader exercise, I do it for the color white^[upper and lower values: (255, 255, 255)] and "Democratic blue"^[lower values: (0, 18, 26), higher values: (102, 212, 255)]. Once this range of values is specified, the computer detects the pixels that do not contain values within this pre-specified range and converts those values to represent the color black. @fig-color-detection-example presents this process.

```{python}
#| label: example detection
#| echo: false
# Define colors to detect
    #* White
        #** Not defined. Default for colorDetector()
    #* Red
republican_red = [232, 27, 35] # target color
red_lower = [93, 9, 12] # lower end of spectrum for red
red_higher = [237, 69, 75] # higher end of spectrum for red

# Load gop image to read
img = cv2.imread("../pre-reg_reports/data/gop_2022.png")

# Detect colors
percent, img_transformed, result = colorDetector(img = img, color_upper = red_higher, color_lower = red_lower)

transformed=cv2.imwrite("../pre-reg_reports/data/gop_2022_transformed.png", img_transformed) # save transformed image

masked=cv2.imwrite("../pre-reg_reports/data/gop_2022_detected.png", result) # save masked image
```

:::{#fig-color-detection-example layout-ncol=2}
![Resized original image]("../pre-reg_reports/data/gop_2022_transformed.png"){#fig-resized}

![Masked]("../pre-reg_reports/data/gop_2022_detected.png"){#fig-masked}

Detecting colors in the GOP logo
:::

I then extract the values in the array that are non-black and calculate the percentage of non-black pixels (as depicted in @eq-img-color-percentage).  

$$
\text{Color} \% = \frac{\text{Non-black}}{\text{Transformed}} \times \frac{\text{Original}_{\text{Height}} + \text{Original}_{\text{Width}}}{2\text{Transformed}_{\text{Height}} + 2\text{Transformed}_{\text{Width}}}
$$ {#eq-img-color-percentage}

```{python}
Markdown(""" For the example in @fig-color-detection-example, about {percent} of the image is red.""".format(percent = f'{percent:.2f}'))
```

With these data, I estimate a mixed effects model with intercept random effects at the district-level and intercept fixed effects at the election-year-level to examine between district, within the election year differences between choices to employ more "partisan" colors on a yard sign based on historical data on electoral performance of partisan and non-partisan candidates for each district.


## Is it *only* electoral differences that shape a campaign's choices?

While this provides useful evidence suggesting systematic differences in choices among campaigns, there is still an open question if whether these differences are *only* the result of electoral differences or if candidate differences influence this; after all, candidates have the ability to shape their campaign. 

I therefore reach out to a number of relatively easy to contact campaign staff for national campaigns and simply ask them "how do you decide what colors to put on a yard sign?" With the handful of these informal interviews, I intend to see whether campaigns percieve that a design choice as simple as color matters for their campaign and what message they are sending to voters. 


# Pre-test {#sec-pre-test}

```{r}
#| label: setup-pre-test-block

# Setup
    #* modularly load functions
box::use(
    haven = haven[read_dta],
    dplyr = dplyr[mutate, case_when, select, rename],
    modelsummary = modelsummary[datasummary_skim, modelsummary],
    rstanarm = rstanarm[stan_polr, stan_glm, R2],
    tibble = tibble[tribble],
    broom = broom[tidy],
    marginaleffects = marginaleffects[marginaleffects, posteriordraws],
    ggplot2 = ggplot2[ggplot, aes, labs, theme_minimal],
    ggdist = ggdist[stat_halfeye]
)
    #* create empty data list object
data = list()
    #* import cleaned dataset 
data[['original']] = read_dta('data/pre-test/sps1.dta')

```

I conducted a pre-test in November 2019 with a sample of over 400 undergraduate students at a large university in the northwestern region of the United States. Students were recruited if they were enrolled in a political science course and were offered extra credit for their participation in the study. The study asked participants to participate in $5$ survey experiments administered by those affiliated with the university's college-level unit. These other survey experiments were focused on capturing local policy issues around urban design, criminal justice, and probing participants about political participation in local and national-level elections. Participants were asked to participate in my survey experiment after one that examined their levels of political participation in local, state, and national elections.

```{r}
#| label: cleaning-block

data[['clean']] = data[['original']] |>
    mutate(
    #* female - gender of respondent
        #** gender coded as: 1 = male, 2 = female
        #** Recode to: 0 = male, 1 = female
    female = case_when(gender == 1 ~ 0, 
                        gender == 2 ~ 1),
    #* age - age of respondent
        #** age coded as: age of respondent
        #** no change
    #* white - race of respondent
        #** race: 1 = asian, 2 = African-American/Black, 3 = Hispanic/Latino, 4 = Native American, 5 = White, 6 = Other
        #** white: 0 = non-white, 1 = white
    white = ifelse(race == 5, 1, 0),
    #* pid - partisan identification
        #** combination of multiple questions
        #** pid: -3 = strong democrat, -2 = democrat, -1 = leans democratic, 0 = independent, 1 = leans republican, 2 = republican, 3 = strong republican
    pid = case_when(pid == 2 & dem1 == 1 ~ -3,
                    pid == 2 & dem1 == 2 ~ -2,
                    pid == 3 & ind1 == 2 ~ -1,
                    pid == 3 & ind1 == 3 ~ 0,
                    pid == 3 & ind1 == 1 ~ 1,
                    pid == 1 & rep1 == 2 ~ 2,
                    pid == 1 & rep1 == 1 ~ 3),
    #* blue_treatment - did they recieve the blue yard sign treatment
        #** q265: 0 = did not display treatment, 1 = did display treatment
        #** new name
    blue_treatment = case_when(q265 == 1 ~ 1,
                                is.na(q265) ~ 0),
    #* red_treatment - did they receive the red yard sign treatment?
        #** q421: 0 = did not display treatment, 1 = did display treatment 
        #** new name
    red_treatment = case_when(q421 == 1 ~ 1,
                            is.na(q421) ~ 0),
    #* white_treatment - did they recieve the white yard sign treatment?
        #** q423: 0 = did not display treatment, 1 = did display treatment
        #** new name
    white_treatment = case_when(q423 == 1 ~ 1, 
                                is.na(q423) ~ 0),
    #* t_party - party of fictional candidate
        #** dr_pid: 1 = republican, 2 = democrat, 3 = neither
        #** t_party: -1 = democrat, 0 = neither, 1 = republican
    t_party = case_when(dr_pid == 2 ~ -1,
                        dr_pid == 3 ~ 0,
                        dr_pid == 1 ~ 1),
    #* t_vote - vote for fictional candidate
        #** dr_info_4: 2 = do not vote for the candidate, 1 = vote for candidate & dr_info_5: 2 = do not avoid candidate, 1 = avoid candidate
        #** t_vote: -1 = avoid candidate, 0 = avoid & vote/do not avoid & do not vote, 1 = vote
    t_vote = case_when(dr_info_4 == 2 & dr_info_5 == 1 ~ -1,
                        dr_info_4 == 1 & dr_info_5 == 1 ~ 0,
                        dr_info_4 == 2 & dr_info_5 == 2 ~ 0,
                        dr_info_4 == 1 & dr_info_5 == 2 ~ 1)
  )
```

```{r}
#| label: tbl-descriptive-stats
#| tbl-cap: Descriptive Statistics

data[['clean']] |>
    select(female, white, age, pid) |>
    rename(`Female` = female, 
            `White` = white,
            `Age` = age,
            `Party ID` = pid) |>
    datasummary_skim(notes = c('Unique coumn includes NA values.', 'Data source: Pre-test experiment.'))
```
@tbl-descriptive-stats presents the descriptive characteristics of the sample. The sample is primarily White with over $80\%$ self-reporting that they are White(coded as: 0 = non-White, 1 = White). The sample also skews slightly female on sex with about $60\%$ of the sample reporting that they are female (coded as: 0 = Male, 1 = Female). The sample also, unsurprisingly, skews young with the average respondent reporting an age of about 22 years old. The average respondent also appears to be an independent but leans Republican (coded as: -3 = strong Democrat, -2 = Democrat, -1 = leans Democrat, 0 = Independent, 1 = leans Republican, 2 = Republican, 3 = strong Republican).

I randomly assign participants into three conditions. The conditions prompt subjects to "Imagine that [they] are driving along a road and see this yard sign" with the same message "Vote for Riley". The conditions vary on the color of the background for the image.^[The images used for the treatments and the particular wording for the dependent variables are included in the Appendix.] In the control condition, the background was white. Then I had a red yard sign and blue yard sign condition. On a separate screen participants were asked a series of questions acting as outcomes of interest.

To provide a preliminary test of **$H_1$** and **$H_2$**, I ask participants to report whether the candidate was a "Republican, Democrat or Independent". Though it does not capture pre-conscious processes, I also wanted to capture the valence the presumed out-or-co-partisan yard sign evokes for subjects. To do this, I ask respondents whether they would "seek out more information about the candidate", "avoid the candidate", "or vote for the candidate". Subjects could respond to one of three questions with a "yes" or "no" response. 

I then combine these questions into a single measure of the subject's valenced response directed toward the candidate. Those that reported they would vote for the candidate or seek out more information, were coded as 1. Those who reported that they would avoid the candidate were coded as -1. Those who reported some combination that represents mixed views or some degree of ambivalence were coded as 0.

I test whether participants presumed that the candidate was of a particular partisan persuasion based only on the color choice of the yard sign alone and whether this is moderated by the partisanship of the participant and what influence it has on valenced reactions directed toward the owner of the sign. I create two indicator variables of the treatment the subjects recieved: whether or not they had the blue or red yard sign treatment. The control condition is treated as the baseline condition when including both indicator variables in the model.

To examine whether subjects presumed that the fictional candidate is affiliated with a particular political party, I fit a model using a cumulative link function from the logistic distribution and specify a prior location of $R^2$ - which represents the proportion of variance the model explains for the discretized latent variable - with an average $R^2$ of $0.3$ when the predictors are at their sample means [see @gelman_et-al_2021_cup, Chapter 15]. I assume this about the $R^2$ as I recognize that color is not going to explain all of the variation in the subjects' ability to detect partisanship, however, my theory suggests that it should have a meaningful impact. Therefore, I choose an expected value of $0.3$, representing that I expect that my treatments should predict about $30\%$ of the variation. I also assume that my errors are normally distributed with a mean of zero. The model is fitted using 6 chains and about 2000 iterations. The results are presented as the average marginal effects for representative values in @fig-pre-experiment-guess^[Full results are presented in the Supplimentary Information.].

```{r}
#| label: model-block
#| eval: false
# Create empty model object
model = list()
# Models
    #** Associate color with partisanship
model[['party_guess']] = stan_polr(as.factor(t_party) ~ blue_treatment + red_treatment, data = data[['clean']], method = 'logistic', prior = R2(0.3, 'mean'), seed = 90210, chains = 6, iter = 2000, adapt_delta = 0.99, refresh = 0)
    #** evaluation of candidate
cand_eval = lm(t_vote ~ blue_treatment + red_treatment + pid + blue_treatment*pid + red_treatment*pid, data = data[['clean']])
model[['cand_eval']]= stan_polr(as.factor(t_vote) ~ blue_treatment + red_treatment + pid + blue_treatment*pid + red_treatment*pid, data = data[['clean']], prior = R2(0.3, 'mean'), seed = 90210, chains = 6, iter = 2000, adapt_delta = 0.99, refresh = 0)
# Store models
saveRDS(model, "ch_1_pre-test_models.rds")
```

```{r}
#| label: load-models

model <- readRDS('ch_1_pre-test_models.rds')
```

```{r}
#| label: fig-pre-experiment-guess
#| fig-cap:
#|  - "Associate color with partisanship"
#| fig-width: 6
associate_color = model[['party_guess']] |>
  marginaleffects() |>
  posteriordraws() |>
  mutate(
    term = case_when(term == 'blue_treatment' ~ 'Blue',
                    term == 'red_treatment' ~ 'Red')
  ) |>
  ggplot(aes(x = draw, y = term)) +
    stat_halfeye() +
    theme_minimal() +
    labs(x = "Average Marginal Effect", y = "Treatment", notes = c('Data source: Pre-test experiment.', '95% credible intervals.'))

associate_color
```

The results suggest that there is some *preliminary* support for my expectation that individuals associate red and blue with Republicans and Democrats. My results suggest that individuals in the treatment with the red yard sign were more likely to presume that the candidate was a Republican, despite having *no* other information about the candidate other than their name and the color of their yard sign.Those in the blue yard sign treatment were more likely to assume that the candidate was a Democrat. The credible intervals for these estimates can be interpreted as the probability that the true estimate is contained in the interval. As neither of these intervals overlap with zero, there is a 95% chance that the true effect is not zero. 

With confidence that the subjects associate the yard signs with the candidate's partisan affiliation, I turn my focus to their evaluations of the owner of the yard sign. I make the same assumptions with the model of candidate evaluations given the treatment. As the outcome of interest is a ordinal categorical variable, I specify a cumulative link function from the logistic distribution and specify a prior location of the $R^2$ with an average of $0.3$ when the predictors are at their sample means. The results of the model is included in the second column of the full set of results in the Supplimentary Information and as the conditional marginal effects of representative values in @fig-pre-experiment-cand-eval.

```{r}
#| label: fig-pre-experiment-cand-eval
#| layout-nrow: 2
#| fig-cap: "Effect of yard sign color on candidate evaluation"
#| fig-subcap:
#|  - "Republicans would vote for candidate with Red yard sign"
#|  - "No difference among partisans in support for candidate with Blue yard sign"
#| fig-width: 6
evaluation_candidate_red = model[['cand_eval']] |>
  marginaleffects::plot_cme(effect = 'red_treatment', condition = 'pid') +
    theme_minimal() +
    labs(y = 'CME of Red treatment on candidate evaluation', x = 'Party ID')
evaluation_candidate_blue = model[['cand_eval']] |>
  marginaleffects::plot_cme(effect = 'blue_treatment', condition = 'pid') +
    theme_minimal() +
    labs(y = 'CME of Blue treatment on candidate evaluation', x = 'Party ID', notes = c('Data source: Pre-test experiment.', '95% credible intervals.'))

evaluation_candidate_red
evaluation_candidate_blue
```

@fig-pre-experiment-cand-eval presents results suggesting that among Republicans recieving the red treatment, they are more likely to indicate that they have a positive valence toward the candidate than Democrats who are more likely to report a negative evaluation of the candidiate. We see that while Democrats recieiving the blue treatment are more likely to also report a positive valence toward the candidate relative to Republicans, the effect is plausibly zero. This may be an artifact of asymmetric political polarization. Some scholars suggest that Republicans are much more group-oriented than Democrats [see @lupton_et-al_2020_bjps], these results may fit with such a narrative. Republicans are reactive to those they may presume to be a co-partisan in a way that Democrats do not appear to be as reactive in a similar magnitude.

The evidence from this pre-test is limited. The experimental design is not testing pre-conscious evaluations. The treatments are explicitly political and was conducted on a convenience sample of those enrolled in political science classes. The ability for individuals to associate partisanship with the treatments are likely overstated. The sample is also quite unrepresentative, so inference is certainly threatened. As I discussed with the third model, I also have omitted variable bias as the result of my outcome being a better measure of approach behaviors for those who are extroverted. 

Though there are problems with the design here, it does serve some purpose for this prospectus. It demonstrates, that dispite its problems, that at some level, when thinking of poltics, color can betray information. It also provides a useful first test of a possible research design to examine what this particular design can and cannot tell me about my proposed mechanism. 

# Discussion

Not only do yard signs matter for electoral strategy, outcomes, and for voter attitudes and perceptions, but I suspect that the color of the yard signs are a partial explanation for these phenomenon.

While yard signs are a simple form of party branding, with richer theorizing about the ways in which diverse types of potentially politically-relevant information allows us to fill some of these gaps. In the case of yard signs, while some may be skeptical of whether yard signs and campaigns, more generally, matter for electoral outcomes, an application of the snap-judgement model on yard signs suggests that they indeed have a potential and provide an explanation as to how it occurs.

Outside of the use of color on yard signs, I suspect that color provides useful information to the public that is processed efficiently. Due to this, voters are able to connect colors like Red and Blue to make assumptions about a political candidate's partisan affiliation. With this information, voters are able to then evaluate the candidate. This is a much simpler task than hearing the candidate's positions on immigration, for example, and then making a connection to their partisan affiliation.